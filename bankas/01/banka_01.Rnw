\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage[OT1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[paper=a4paper,top=20.5mm,
bottom=13.5mm,left=16.5mm,right=13.5mm,includefoot]{geometry}

\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Corr}{Corr}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\rk}{rk}
\newcommand{\E}{\mathbb{E}}
\newcommand{\e}{\varepsilon}

\begin{document}


Банка прикончена!!!!

\textbf{Задача 1.} При помощи метода наименьших квадратов найдите оценку неизвестного параметра $\theta$ в следующих моделях:

\begin{enumerate}
\item[(a)] $y_i = \theta + \theta x_i + \varepsilon_i$
\item[(b)] $y_i = \theta - \theta x_i + \e_i$
\item[(c)] $\text{ln} y_i = \theta + \text{ln} x_i + \e_i$
\item[(d)] $y_i = \theta + x_i + \e_i$
\item[(e)] $y_i = 1 + \theta x_i + \e_i$
\item[(f)] $y_i = \theta / x_i + \e_i$
\item[(g)] $y_i = \theta x_{i1} + (1-\theta)x_{i2}+\e_i$
\end{enumerate}

\textbf{Задача 2.} Покажите, что для моделей $y_i= \alpha + \beta x_i + \e_i$, $z_i = \gamma + \delta x_i + \upsilon_i$ и $y_i + z_i = \mu + \lambda x_i + \xi_i$ МНК-оценки связаны соотношениями $\hat{\mu}=\hat{\alpha}+\hat{\gamma}$ и $\hat{\lambda}=\hat{\beta} + \hat{\delta}$.

\textbf{Задача 3.} Найдите МНК-оценки параметров $\alpha$ и $\beta$ в модели $y_i = \alpha + \beta y_i + \e_i$.

\textbf{Задача 4.} Рассмотрите модели $y_i = \alpha + \beta (y_i + z_i) + \e_i$, $z_i = \gamma + \delta(y_i+z_i) + \e_i$ и покажите, что $\hat{\alpha} + \hat{\gamma} = 0$ и $\hat{\beta} + \hat{\delta} = 1$.

\textbf{Задача 5.} Как связаны МНК-оценки параметров $\alpha, \beta$ и $\gamma, \delta$ в моделях $y_i = \alpha + \beta x_i + \e_i$ и $z_i = \gamma + \delta x_i + \upsilon_i$, если $z_i = 2 y_i$.

\textbf{Задача 6.} Для модели $y_i = \beta_1 x_{i1} + \beta_2 x_{i2} + \e_i$ решите условную задачу о наименьших квадратах: $Q(\beta_1, \beta_2) := \sum_{i=1}^n (y_i - \beta_1 x_{i1} - \beta_2 x_{i2})^2 \rightarrow \underset{\beta_1 + \beta_2 = 1}{\min}$

\textbf{Задача 7.} Рассмотрите классическую линейную регрессионную модель $y_i = \beta x_i + \e_i$. Найдите $\E \hat{\beta}$. Какие из следующих оценок параметра $\beta$ являются несмещенными:

\begin{enumerate}
\item $\hat{\beta} = \frac{y_1}{x_1}$
\item $\hat{\beta} = \frac{1}{2} \frac{y_1}{x_1} + \frac{1}{2} \frac{y_n}{x_n}$
\item $\hat{\beta} = \frac{1}{n}  \frac{y_1}{x_1} + \ldots + \frac{y_n}{x_n} $
\item $\hat{\beta} = \frac{\overline{y}}{\overline{x}}$
\item $\hat{\beta} = \frac{y_n - y_1}{x_n - x_1}$
\item $\hat{\beta} = \frac{1}{2} \frac{y_2 - y_1}{x_2 - x_1} + \frac{1}{2} \frac{y_n - y_{n-1}}{x_n - x_{n-1}}$
\item $\hat{\beta} = \frac{1}{n} \frac{y_2 - y_1}{x_2 - x_1} + \frac{1}{n} \frac{y_3 - y_2}{x_3 - x_2} + \ldots + \frac{1}{n} \frac{y_n - y_{n-1}}{x_n - x_{n-1}}$
\item $\hat{\beta} = \frac{1}{n-1}  \frac{y_2 - y_1}{x_2 - x_1} + \frac{y_3 - y_2}{x_3 - x_2} + \ldots + \frac{y_n - y_{n-1}}{x_n - x_{n-1}} $
\item $\hat{\beta} = \frac{x_1 y_1 + \ldots + x_n y_n}{x_1^2 + \ldots + x_n^2}$
\item $\hat{\beta} = \frac{1}{2} \frac{y_n - y_1}{x_n - x_1} + \frac{1}{2n}  \frac{y_1}{x_1} + \ldots + \frac{y_n}{x_n} $
\item $\hat{\beta} =  \frac{1}{2} \frac{y_n - y_1}{x_n - x_1} + \frac{1}{2} \frac{x_1 y_1 + \ldots + x_n y_n}{x_1^2 + \ldots + x_n^2}$
\item $\hat{\beta} = \frac{\sum_{i=1}^n (x_i - \overline{x})(y_i - \overline{y})}{\sum_{i=1}^n (x_i - \overline{x^2})^2}$
\item $\hat{\beta} = \frac{\sum_{i=1}^n (x_i - \overline{x})(\overline{y} - y_i)}{\sum_{i=1}^n (x_i - \overline{x^2})^2}$
\item $\hat{\beta} = \frac{y_1 + 2 y_2 + \ldots + n y_n}{x_1 + 2 x_2 + \ldots + n x_n}$
\item $\hat{\beta} = \frac{\sum_{i=1}^n i(y_i - \overline{y})}{\sum_{i=1}^n i(x_i - \overline{x})}$
\item $\hat{\beta} = \frac{1}{n} \sum_{i=1}^n \frac{y_i}{x_i}$
\item $\hat{\beta} = \frac{1}{n} \sum_{i=1}^n \frac{y_i - \overline{y}}{x_i - \overline{x}}$
\end{enumerate}

\textbf{Задача 8.} Рассмотрите классическую линейную регрессионную модель $y_i = \beta x_i + \e_i$. Найдите $\Var(\hat{\beta})$.

\begin{enumerate}
\item $\hat{\beta} = \frac{y_1}{x_1}$
\item $\hat{\beta} = \frac{1}{2} \frac{y_1}{x_1} + \frac{1}{2} \frac{y_n}{x_n}$
\item $\hat{\beta} = \frac{1}{n}  \frac{y_1}{x_1} + \ldots + \frac{y_n}{x_n} $
\item $\hat{\beta} = \frac{\overline{y}}{\overline{x}}$
\item $\hat{\beta} = \frac{y_n - y_1}{x_n - x_1}$
\item $\hat{\beta} = \frac{1}{2} \frac{y_2 - y_1}{x_2 - x_1} + \frac{1}{2} \frac{y_n - y_{n-1}}{x_n - x_{n-1}}$
\item $\hat{\beta} = \frac{x_1 y_1 + \ldots + x_n y_n}{x_1^2 + \ldots + x_n^2}$
\item $\hat{\beta} = \frac{\sum_{i=1}^n (x_i - \overline{x})(y_i - \overline{y})}{\sum_{i=1}^n (x_i - \overline{x^2})^2}$
\item $\hat{\beta} = \frac{\sum_{i=1}^n (x_i - \overline{x})(\overline{y} - y_i)}{\sum_{i=1}^n (x_i - \overline{x^2})^2}$
\item $\hat{\beta} = \frac{y_1 + 2 y_2 + \ldots + n y_n}{x_1 + 2 x_2 + \ldots + n x_n}$
\item $\hat{\beta} = \frac{\sum_{i=1}^n i(y_i - \overline{y})}{\sum_{i=1}^n i(x_i - \overline{x})}$
\item $\hat{\beta} = \frac{1}{n} \sum_{i=1}^n \frac{y_i}{x_i}$
\item $\hat{\beta} = \frac{1}{n} \sum_{i=1}^n \frac{y_i - \overline{y}}{x_i - \overline{x}}$
\end{enumerate}

\textbf{Задача 9.} Рассмотрите классическую линейную регрессионную модель $y_i = \beta \cdot i + \e_i$, $i=1, \ldots, n$. Какая из оценок $\hat{\beta}$ и $\tilde{\beta}$ является более эффективной?

\begin{enumerate}
\item $\hat{\beta} = y_1$ и $\tilde{\beta} = y_2/2$
\item $\hat{\beta} = y_1$ и $\tilde{\beta} = \frac{1}{2} y_1 + \frac{1}{2} \frac{y_2}{2}$
\item $\hat{\beta} = \frac{1}{n}  \frac{y_1}{1} + \ldots + \frac{y_n}{n} $ и $\tilde{\beta} = \frac{1 \cdot y_1 + \ldots + n \cdot y_n}{1^2 + \ldots + n^2}$
\end{enumerate} 

\textbf{Задача 10.} Известно, что случайные величины $x_1$, $x_2$ и $x_3$ имеют следующие характеристики: 
\begin{enumerate}
\item $\E(x_1) = 5$, $\E(x_2) = 10$, $\E(x_3) = 8$
\item $\Var  (x_1) = 6$, $\Var  (x_2) = 14$, $\Var  (x_3) = 1$
\item $\Cov  (x_1, x_2) = 3$, $\Cov  (x_1, x_3) = 1$, $\Cov  (x_2, x_3) = 0$
\end{enumerate}
Пусть случайные величины $y_1$, $y_2$ и $y_3$, представляют собой линейные комбинации случайных величин $X_1$, $X_2$ и $X_3$:
$$y_1 = x_1 + 3x_2 - 2x_3$$
$$y_2 = 7x_1 - 4x_2 + x_3$$
$$y_3 = -2x_1 - x_2 + 4x_3$$

\begin{enumerate}
\item Выпишите математическое ожидание и ковариационную матрицу случайного вектора $x =  \begin{bmatrix}
x_1 & x_2 & x_3\\
\end{bmatrix} ^T$
\item Напишите матрицу $A$, которая позволяет перейти от случайного вектора $x =  \begin{bmatrix}
x_1 & x_2 & x_3\\
\end{bmatrix} ^T$ к случайному вектору $y =  \begin{bmatrix}
y_1 & y_2 & y_3\\
\end{bmatrix} ^T$
\item С помощью матрицы $A$ найдите математическое ожидание и ковариационную матрицу случайного вектора $y =  \begin{bmatrix}
y_1 & y_2 & y_3\\
\end{bmatrix} ^T$
\end{enumerate}

\textbf{Задача 11.} Пусть $x =  \begin{bmatrix}
x_1 & x_2\\
\end{bmatrix} ^T$ --- случайный вектор, имеющий двумерное нормальное распределение с математическим ожиданием $\mu =  \begin{bmatrix}
1 & 2\\
\end{bmatrix} ^T$ и ковариационной матрицей $\Sigma = 
\begin{bmatrix}
2 & 1 \\
1 & 2 \\
\end{bmatrix} $. 

\begin{enumerate}
\item Найдите $\Sigma^{-1}$
\item Найдите $\Sigma^{-1/2}$
\item Найдите математическое ожидание и ковариационную матрицу случайного вектора $y = \Sigma^{-1/2} \cdot (x - \mu)$
\item Какое распределение имеет вектор $y$ из предыдущего пункта?
\item Найдите распределение случайной величины $q = (x- \mu)^T \cdot \Sigma^{-1} \cdot (x - \mu)$
\end{enumerate}

\textbf{Задача 12.} Пусть $z =  \begin{bmatrix}
z_1 & z_2 & z_3\\
\end{bmatrix} ^T \sim N(0, I_{3x3})$, $b =  \begin{bmatrix}
1 & 2 & 3\\
\end{bmatrix} ^T$,

$A =  \begin{bmatrix}
1 & 1 & 1 \\
0 & 1 & 1 \\
0 & 0 & 1 \\
\end{bmatrix} $, $K =  \begin{bmatrix}
1 & 0 & 0 \\
0 & 1/2 & 1/2 \\
0 & 1/2 & 1/2 \\
\end{bmatrix} $.

\begin{enumerate}
\item Найдите $\E x$ и $\Var (x)$ случайного вектора $x = A \cdot z + b$
\item Найдите распределение случайного вектора $x$
\item Найдите $\E q$ случайной величины $q = z^T \cdot K \cdot z$
\item Найдите распределение случайной величины $q$
\end{enumerate}

\textbf{Задача 13.} Пусть регрессионная модель $y_i = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \e_i$, $i = 1, \ldots, n$, задана в матричном виде при помощи уравнения $y = X \beta + \e$, где $\beta =  \begin{bmatrix}
\alpha & \beta_1 & \beta_2\\
\end{bmatrix} ^T$. Известно, что $\E \e = 0$ и $\Var (\e) = 4 \cdot I$. Известно также, что:

$y =  \begin{bmatrix}
1 \\
2 \\
3 \\
4 \\
5 \\
\end{bmatrix} $, $X =  \begin{bmatrix}
1 & 0 & 0 \\
1 & 0 & 0 \\
1 & 1 & 0 \\
1 & 1 & 0 \\
1 & 1 & 1 \\
\end{bmatrix} $

Для удобства расчётов ниже приведены матрицы:

$X^T X =  \begin{bmatrix}
5 & 3 & 1 \\
3 & 3 & 1 \\
1 & 1 & 1 \\
\end{bmatrix} $ и $(X^T X)^{-1} =  \begin{bmatrix}
0.5 & -0.5 & 0 \\
-0.5 & 1 & -0.5 \\
0 & -0.5 & 1.5 \\
\end{bmatrix} $.

Найдите:
\begin{enumerate}
\item $\Var (\e_1)$
\item $\Var (\alpha)$
\item $\Var (\hat{\alpha})$
\item $\widehat{\Var }(\hat{\alpha})$
\item $\E (\hat{\alpha}^2) - \alpha^2$
\item $\Cov (\hat{\beta}_1, \hat{\beta}_2)$
\item $\widehat{\Cov }(\hat{\beta}_1, \hat{\beta}_2)$
\item $\Var (\hat{\beta}_1 - \hat{\beta}_2)$
\item $\widehat{\Var }(\hat{\beta}_1 - \hat{\beta}_2)$
\item $\Var (\beta_1 - \beta_2)$
\item $\Corr (\hat{\beta}_1, \hat{\beta}_2)$
\item $\widehat{\Corr}(\hat{\beta}_1, \hat{\beta}_2)$
\item $\E (\hat{\sigma}^2)$
\item $\hat{\sigma}^2$
\end{enumerate}

\textbf{Задача 14.}  Пусть $\xi_1, \xi_2, \xi_3$ --- случайные величины, такие что $\Var (\xi_1) = 2$, $\Var (\xi_2) = 3$, $\Var (\xi_3) = 4$, $\Cov (\xi_1, \xi_2) = 1$, $\Cov (\xi_1, \xi_3) = -1$, $\Cov (\xi_2, \xi_3) = 0$. Пусть $\xi =  \begin{bmatrix}
\xi_1 & \xi_2 & \xi_3 \\
\end{bmatrix} ^T$. Найдите $\Var (\xi)$ и $\Var (\xi_1 + \xi_2 + \xi_3)$.

\solution{ По определению ковариационной матрицы:

$\Var (\xi) =  \begin{bmatrix}
\Var (\xi_1) & \Cov (\xi_1, \xi_2) & \Cov (\xi_1, \xi_3) \\
\Cov (\xi_2, \xi_1) & \Var (\xi_2) & \Cov (\xi_2, \xi_3) \\
\Cov (\xi_3, \xi_1) & \Cov (\xi_3, \xi_2) & \Var (\xi_3) \\
\end{bmatrix}  =  \begin{bmatrix}
2 & 1 & -1 \\
1 & 3 & 0 \\
-1 & 0 & 4 \\
\end{bmatrix} $

$\Var (\xi_1 + \xi_2 + \xi_3)  = \Var   \begin{bmatrix} 
 \begin{bmatrix}
1 & 1 & 1 \\
\end{bmatrix}  &  \begin{bmatrix}
\xi_1 \\
\xi_2 \\
\xi_3 \\
\end{bmatrix} 
\end{bmatrix}  =  \begin{bmatrix}
1 & 1 & 1 \\
\end{bmatrix}  \Var   \begin{bmatrix}
\xi_1 \\
\xi_2 \\
\xi_3 \\
\end{bmatrix}   \begin{bmatrix}
1 \\
1 \\
1 \\
\end{bmatrix}  =  \begin{bmatrix}
1 & 1 & 1 \\
\end{bmatrix}   \begin{bmatrix}
2 & 1 & -1 \\
1 & 3 & 0 \\
-1 & 0 & 4 \\
\end{bmatrix}   \begin{bmatrix}
1 \\
1 \\
1 \\
\end{bmatrix}  = 9$
}

\textbf{Задача 15.} Пусть $h =  \begin{bmatrix}
\xi_1 \\
\xi_2 \\
\end{bmatrix} $; $\E (h) =  \begin{bmatrix}
1\\
2\\
\end{bmatrix} $; $\Var (h) =  \begin{bmatrix}
2 & 1 \\
1 & 2 \\
\end{bmatrix} $; $z_1 =  \begin{bmatrix}
\eta_1 \\
\eta_2 \\
\end{bmatrix}  =  \begin{bmatrix}
0 & 0 \\
0 & 1 \\
\end{bmatrix}   \begin{bmatrix}
\xi_1 \\
\xi_2 \\
\end{bmatrix} $. Найдите $\E (z_1)$ и $\Var (z_1)$.

\solution{ $\E (z_1) = \E   \begin{bmatrix}
 \begin{bmatrix}
0 & 0 \\
0 & 1 \\
\end{bmatrix}  &  \begin{bmatrix}
\xi_1 \\
\xi_2 \\
\end{bmatrix}  \\
\end{bmatrix}  =  \begin{bmatrix}
0 & 0 \\
0 & 1 \\
\end{bmatrix}  \E   \begin{bmatrix}
\xi_1 \\
\xi_2 \\
\end{bmatrix}  =  \begin{bmatrix}
0 & 0 \\
0 & 1 \\
\end{bmatrix}   \begin{bmatrix}
1\\
2\\
\end{bmatrix}  =  \begin{bmatrix}
0\\
2\\
\end{bmatrix} $

$\Var (z_1) = \Var   \begin{bmatrix}
 \begin{bmatrix}
0 & 0 \\
0 & 1 \\
\end{bmatrix}  &  \begin{bmatrix}
\xi_1 \\
\xi_2 \\
\end{bmatrix}  \\
\end{bmatrix}  =  \begin{bmatrix}
0 & 0 \\
0 & 1 \\
\end{bmatrix}  \Var   \begin{bmatrix}
\xi_1 \\
\xi_2 \\
\end{bmatrix}   \begin{bmatrix}
0 & 0 \\
0 & 1 \\
\end{bmatrix} ^T =  \begin{bmatrix}
0 & 0 \\
0 & 1 \\
\end{bmatrix}   \begin{bmatrix}
2 & 1 \\
1 & 2 \\
\end{bmatrix}   \begin{bmatrix}
0 & 0 \\
0 & 1 \\
\end{bmatrix} ^T = \\
\begin{bmatrix}
0 & 0 \\
0 & 1 \\
\end{bmatrix}   \begin{bmatrix}
0 & 1 \\
0 & 2 \\
\end{bmatrix}  =  \begin{bmatrix}
0 & 0 \\
0 & 2 \\
\end{bmatrix} $
}

\textbf{Задача 16.} Пусть $h =  \begin{bmatrix}
\xi_1 \\
\xi_2 \\
\end{bmatrix} $; $\E (h) =  \begin{bmatrix}
1\\
2\\
\end{bmatrix} $; $\Var (h) =  \begin{bmatrix}
2 & 1 \\
1 & 2 \\
\end{bmatrix} $; $z_2 =  \begin{bmatrix}
\eta_1 \\
\eta_2 \\
\end{bmatrix}  =  \begin{bmatrix}
0 & 0 \\
0 & 1 \\
\end{bmatrix}   \begin{bmatrix}
\xi_1 \\
\xi_2 \\
\end{bmatrix}  +  \begin{bmatrix}
1\\
1\\
\end{bmatrix} $. Найдите $\E (z_2)$ и $\Var (z_2)$

\solution{ $\E (z_2) = \E   \begin{bmatrix}
 \begin{bmatrix}
0 & 0 \\
0 & 1 \\
\end{bmatrix}  &  \begin{bmatrix}
\xi_1 \\
\xi_2 \\
\end{bmatrix}  & + &  \begin{bmatrix}
1\\
1\\
\end{bmatrix}  \\
\end{bmatrix}  =  \begin{bmatrix}
0 & 0 \\
0 & 1 \\
\end{bmatrix}  \E   \begin{bmatrix}
\xi_1 \\
\xi_2 \\
\end{bmatrix}  +  \begin{bmatrix}
1\\
1\\
\end{bmatrix}  =  \begin{bmatrix}
0 & 0 \\
0 & 1 \\
\end{bmatrix}   \begin{bmatrix}
1\\
2\\
\end{bmatrix}  +  \begin{bmatrix}
1\\
1\\
\end{bmatrix}  =  \begin{bmatrix}
0\\
2\\
\end{bmatrix} +  \begin{bmatrix}
1\\
1\\
\end{bmatrix}  =  \begin{bmatrix}
1\\
3\\
\end{bmatrix} $

Поскольку $z_2 = z_1 +  \begin{bmatrix}
1\\
1\\
\end{bmatrix} $, где $z_1$ --- случайный вектор из предыдущей задачи, то $\Var (z_2) = \Var (z_1)$. Сдвиг случайного вектора на вектор-константу не меняет его ковариационную матрицу. 
}

\textbf{Задача 17.} Пусть $h =  \begin{bmatrix}
\xi_1 \\
\xi_2 \\
\end{bmatrix} $; $\E (h) =  \begin{bmatrix}
1\\
2\\
\end{bmatrix} $; $\Var (h) =  \begin{bmatrix}
2 & 1 \\
1 & 2 \\
\end{bmatrix} $; $z_3 =  \begin{bmatrix}
\eta_1 \\
\eta_2 \\
\end{bmatrix}  =  \begin{bmatrix}
\xi_1 \\
\xi_2 \\
\end{bmatrix}  -  \begin{bmatrix}
\E \xi_1 \\
\E \xi_2 \\
\end{bmatrix} $. Найдите $\E (z_3)$ и $\Var (z_3)$

\solution{ \textit{В данном примере проиллюстрирована процедура центрирования случайного вектора --- процедура вычитания из случайного вектора его математического ожидания.}

$\E (z_3) = \E   \begin{bmatrix}
 \begin{bmatrix}
\xi_1 \\
\xi_2 \\
\end{bmatrix}  & - &  \begin{bmatrix}
\E  \xi_1 \\
\E  \xi_2 \\
\end{bmatrix}  \\
\end{bmatrix}  = \E   \begin{bmatrix}
\xi_1 \\
\xi_2 \\
\end{bmatrix}  - \E   \begin{bmatrix}
\E  \xi_1 \\
\E  \xi_2 \\
\end{bmatrix}  =  \begin{bmatrix}
\E  \xi_1 \\
\E  \xi_2 \\
\end{bmatrix}  -  \begin{bmatrix}
\E  \xi_1 \\
\E  \xi_2 \\
\end{bmatrix}  =  \begin{bmatrix}
0\\
0\\
\end{bmatrix} $

Заметим, что вектор $z_3$ отличается от вектора $z_1$ (из задачи 15) сдвигом на вектор-константу $ \begin{bmatrix}
\E  \xi_1 \\
\E  \xi_2 \\
\end{bmatrix} $, поэтому $\Var (z_3) = \Var (z_1)$.
}

\textbf{Задача 18.} Пусть $r_1$, $r_2$ и $r_3$ --- годовые доходности трёх рисковых финансовых инструментов. Пусть $\alpha_1$, $\alpha_2$ и $\alpha_3$ --- доли, с которыми данные инструменты входят в портфель инвестора. Считаем, что $\sum_{i=1}^3 \alpha_i = 1$ и $\alpha_i \geqslant 0$ для всех $i=1,2,3$. Пусть $r =  \begin{bmatrix}
r_1 & r_2 & r_3\\
\end{bmatrix} ^T$, $\E (r) =  \begin{bmatrix}
a_1 & a_2 & a_3\\
\end{bmatrix} ^T$, $\Var (r) =  \begin{bmatrix}
c_{11} & c_{12} & c_{13} \\
c_{21} & c_{22} & c_{23} \\
c_{31} & c_{32} & c_{33} \\
\end{bmatrix} $. Параметры $\left\lbrace a_i \right\rbrace$ и $\left\lbrace c_i \right\rbrace$ известны.

\begin{enumerate}
\item Найдите годовую доходность портфеля П инвестора
\item Докажите, что дисперсия доходности портфеля П равна $\sum_{i=1}^3 \sum_{j=1}^3 \alpha_i c_{ij} \alpha_j$
\item Для случая $\alpha_1 = 0.1$, $\alpha_2 = 0.5$, $\alpha3 = 0.4$, $\E (r) =  \begin{bmatrix}
a_1 & a_2 & a_3\\
\end{bmatrix} ^T =  \begin{bmatrix}
0.10 & 0.06 & 0.05 \\
\end{bmatrix} ^T$, $\Var (r) =  \begin{bmatrix}
0.04 & 0 & -0.005\\
0 & 0.01 & 0\\
-0.005 & 0 & 0.0025\\
\end{bmatrix} $ найдите $\E (\text{П})$ и $\Var (\text{П})$
\end{enumerate}

\textbf{Задача 19.} Пусть $h =  \begin{bmatrix}
\xi_1 \\
\xi_2 \\
\end{bmatrix} $; $\E (h) =  \begin{bmatrix}
1\\
2\\
\end{bmatrix} $; $\Var (h) =  \begin{bmatrix}
2 & 1 \\
1 & 2 \\
\end{bmatrix} $; $z_3 =  \begin{bmatrix}
\eta_1 \\
\eta_2 \\
\end{bmatrix}  =  \begin{bmatrix}
\xi_1 \\
\xi_2 \\
\end{bmatrix}  -  \begin{bmatrix}
\E \xi_1 \\
\E \xi_2 \\
\end{bmatrix} $; $z_4 = \Var (h)^{-1/2} z_3$. Найдите $\E (z_4)$ и $\Var (z_4)$

\textbf{Задача 20.} Пусть $h =  \begin{bmatrix}
\xi_1 \\
\xi_2 \\
\end{bmatrix} $; $\E (h) =  \begin{bmatrix}
1\\
2\\
\end{bmatrix} $; $\Var (h) =  \begin{bmatrix}
3 & 1 \\
1 & 3 \\
\end{bmatrix} $; $z_3 =  \begin{bmatrix}
\eta_1 \\
\eta_2 \\
\end{bmatrix}  =  \begin{bmatrix}
\xi_1 \\
\xi_2 \\
\end{bmatrix}  -  \begin{bmatrix}
\E \xi_1 \\
\E \xi_2 \\
\end{bmatrix} $; $z_4 = \Var (h)^{-1/2} z_3$. Найдите $\E (z_4)$ и $\Var (z_4)$
\end{document}