\documentclass[pdftex,12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}

\usepackage[paper=a4paper,top=13.5mm, bottom=13.5mm,left=16.5mm,right=13.5mm,includefoot]{geometry}
\usepackage[pdftex,unicode,colorlinks=true,urlcolor=blue,hyperindex,breaklinks]{hyperref} 

\usepackage{dcolumn}
\usepackage{color}
%\usepackage{wasysym}
\usepackage{floatflt}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{setspace}
\usepackage{indentfirst} % indent first line

%\usepackage{savesym} % avoid conflicting definitions with amsmath
%\savesymbol{iint}
%\savesymbol{iiint}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\def\baselinestretch{1.5}

\DeclareMathOperator{\Corr}{Corr}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\rk}{rk}
\newcommand{\E}{\mathbb{E}}

%\savesymbol{P}
\renewcommand{\P}{\mathbb{P}} % somewhere \P is already defined :)
\newcommand{\e}{\varepsilon}

\begin{document}

<<message=FALSE, echo=FALSE>>=
require(xtable)
require(econru)
@

Банка внесена в задачник!

\begin{enumerate}

\item Пусть $\e = (\e_1, \e_2, \e_3)'\sim N (0,I)$ и матрица $A$ представлена ниже. Найдите $\E(\e'A\e)$ и распределение случайной величины $\e'A\e$.

\begin{enumerate}
\item 
$\begin{pmatrix} 2/3 & -1/3 & 1/3 \\ -1/3 & 2/3 & 1/3 \\ 1/3 & 1/3 & 2/3 \end{pmatrix}$
<<results='asis', echo=FALSE>>=
a <- matrix(c(2/3, -1/3, 1/3, -1/3, 2/3, 1/3, 1/3, 1/3, 2/3), nrow=3, ncol=3, byrow = FALSE, dimnames = NULL)
@
\item 
$\begin{pmatrix} 2/3 & -1/3 & -1/3 \\ -1/3 & 2/3 & -1/3 \\ -1/3 & -1/3 & 2/3 \end{pmatrix}$
<<results='asis', echo=FALSE>>=
e <- matrix(c(2/3, -1/3, -1/3, -1/3, 2/3, -1/3, -1/3, -1/3, 2/3), nrow=3, ncol=3, byrow = FALSE, dimnames = NULL)
@
\item 
$\begin{pmatrix} 1/3 & 1/3 & -1/3 \\ 1/3 & 1/3 & -1/3 \\ -1/3 & -1/3 & 1/3 \end{pmatrix}$
<<results='asis', echo=FALSE>>=
b <- matrix(c(1/3, 1/3, -1/3, 1/3, 1/3, -1/3, -1/3, -1/3, 1/3), nrow=3, ncol=3, byrow = FALSE, dimnames = NULL)
@
\item
$\begin{pmatrix} 1/3 & 1/3 & 1/3 \\ 1/3 & 1/3 & 1/3 \\ 1/3 & 1/3 & 1/3 \end{pmatrix}$
<<results='asis', echo=FALSE>>=
f <- matrix(c(1/3, 1/3, 1/3, 1/3, 1/3, 1/3, 1/3, 1/3, 1/3), nrow=3, ncol=3, byrow = FALSE, dimnames = NULL)
@
\item
$\begin{pmatrix} 1/2 & 0 & 1/2 \\ 0 & 1 & 0 \\ 1/2 & 0 & 1/2 \end{pmatrix}$
<<results='asis', echo=FALSE>>=
g <- matrix(c(1/2, 0, 1/2, 0, 1, 0, 1/2, 0, 1/2), nrow=3, ncol=3, byrow = FALSE, dimnames = NULL)
@
\item
$\begin{pmatrix} 1/2 & 0 & -1/2 \\ 0 & 1 & 0 \\ -1/2 & 0 & 1/2 \end{pmatrix}$
<<results='asis', echo=FALSE>>=
h <- matrix(c(1/2, 0, -1/2, 0, 0, 0, -1/2, 0, 1/2), nrow=3, ncol=3, byrow = FALSE, dimnames = NULL)
@
\item
$\begin{pmatrix} 1/2 & -1/2 & 0 \\ -1/2 & 1/2 & 0 \\ 0 & 0 & 1 \end{pmatrix}$
<<results='asis', echo=FALSE>>=
i <- matrix(c(1/2, -1/2, 0, -1/2, 1/2, 0, 0, 0, 1), nrow=3, ncol=3, byrow = FALSE, dimnames = NULL)
@
\item
$\begin{pmatrix} 1/2 & 1/2 & 0 \\ 1/2 & 1/2 & 0 \\ 0 & 0 & 0 \end{pmatrix}$
<<results='asis', echo=FALSE>>=
j <- matrix(c(1/2, 1/2, 0, 1/2, 1/2, 0, 0, 0, 0), nrow=3, ncol=3, byrow = FALSE, dimnames = NULL)
@
\item 
$\begin{pmatrix} 0.8 & 0.4 & 0 \\ 0.4 & 0.2 & 0 \\ 0 & 0 & 1 \end{pmatrix}$
<<results='asis', echo=FALSE>>=
c <- matrix(c(0.8, 0.4, 0, 0.4, 0.2, 0, 0, 0, 1), nrow=3, ncol=3, byrow = FALSE, dimnames = NULL)
@
\item 
$\begin{pmatrix} 0.2 & -0.4 & 0 \\ -0.4 & 0.8 & 0 \\ 0 & 0 & 0 \end{pmatrix}$
<<results='asis', echo=FALSE>>=
d <- matrix(c(0.2, -0.4, 0, -0.4, 0.8, 0, 0, 0, 0), nrow=3, ncol=3, byrow = FALSE, dimnames = NULL)
@
\end{enumerate}


\item Пусть $\e = (\e_1, \e_2, \e_3)'\sim N (0,I)$. Найдите $\E(\e'P\e)$ и распределение случайной величины $\e'P\e$, если $P = X(X'X)^{-1}X'$ и матрица $X'$ представлена ниже.
\begin{enumerate}
\item
<<results='asis',echo=FALSE>>=
A <- matrix(as.integer(c(1,1,1)), nrow=1, ncol=3, byrow = FALSE, dimnames = NULL)
xmatrix(A)
@
\item
<<results='asis',echo=FALSE>>=
B <- matrix(as.integer(c(1,2,3)), nrow=1, ncol=3, byrow = FALSE, dimnames = NULL)
xmatrix(B)
@
\item
<<results='asis',echo=FALSE>>=
C <- matrix(as.integer(c(1,0,1,0,1,1)), nrow=2, ncol=3, byrow = FALSE, dimnames = NULL)
xmatrix(C)
@
\item
<<results='asis',echo=FALSE>>=
D <- matrix(as.integer(c(1,1,1,2,1,3)), nrow=2, ncol=3, byrow = FALSE, dimnames = NULL)
xmatrix(D)
@
\item
<<results='asis',echo=FALSE>>=
E <- matrix(as.integer(c(1,0,0,1,1,0,1,1,1)), nrow=3, ncol=3, byrow = FALSE, dimnames = NULL)
xmatrix(E)
@
\end{enumerate}

\item Пусть $y = X\beta + \e$ --- регрессионная модель.
\begin{enumerate}
\item Сформулируйте теорему Гаусса-Маркова
\item Верно ли, что оценка $\hat{\beta} = (X'X)^{-1}X'y$ несмещённая?
\item В условиях теоремы Гаусса-Маркова найдите ковариационную матрицу $\hat{\beta}$
\end{enumerate}

\item Пусть $y = X\beta + \e$ --- регрессионная модель и $\tilde{\beta} = ((X'X)^{-1}X'+ A)y$ --- несмещённая оценка вектора неизвестных параметров $\beta$. Верно ли, что $AX=0$?

\item Пусть $y = X\beta + \e$ --- регрессионная модель, $X = \begin{pmatrix} 1 & 0 \\ 1 & 1 \\ 1 & 1 \end{pmatrix}$, $y = \begin{pmatrix} 1 \\ 2 \\ 3 \end{pmatrix}$, $\beta = \begin{pmatrix} \beta_1 \\ \beta_2 \end{pmatrix}$, $\e = \begin{pmatrix} \e_1 \\ \e_2 \\ \e_3 \end{pmatrix}$, $\E(\e)$ = 0, $\Var(\e) = \sigma^2 I$. Найдите коэффициент корреляции $\Corr(\hat{\beta_1},\hat{\beta_2})$.
<<echo=FALSE>>=
X <- matrix(as.integer(c(1,1,1,0,1,1)), nrow=3, byrow = FALSE, dimnames = NULL)
y <- c(1,2,3)
@


\item Пусть  $x = \begin{pmatrix} x_1 \\ x_2 \end{pmatrix}$, $\E(x) = \begin{pmatrix} 1 \\ 2 \end{pmatrix}$, $\Var(x) = \begin{pmatrix} 2 & 1 \\ 1 & 2 \end{pmatrix}$. Найдите $\E(y)$, $\Var(y)$ и $\E(z)$, если
\begin{enumerate}
\item $y = x - \E(x)$
\item $y = \Var(x)x$
\item $y = \Var(x)(x - \E(x))$
\item $y = \Var(x)^{-1}(x - \E(x))$
\item $y = \Var(x)^{-1/2}(x - \E(x))$
\item $z = (x - \E(x))'\Var(x)(x - \E(x))$
\item $z = (x - \E(x))'\Var(x)^{-1}(x - \E(x))$
\item $z = x'\Var(x)x$
\item $z = x'\Var(x)^{-1}x$
\end{enumerate}
<<echo=FALSE>>=
ex <- c(1,2)
varx <- matrix(as.integer(c(2,1,1,2)), nrow=2, byrow = FALSE, dimnames = NULL)
@

\item Пусть  $x = \begin{pmatrix} x_1 \\ x_2 \end{pmatrix}$, $\E(x) = \begin{pmatrix} 1 \\ 4 \end{pmatrix}$, $\Var(x) = \begin{pmatrix} 4 & 1 \\ 1 & 4 \end{pmatrix}$. Найдите $\E(y)$, $\Var(y)$ и $\E(z)$, если
\begin{enumerate}
\item $y = x - \E(x)$
\item $y = \Var(x)x$
\item $y = \Var(x)(x - \E(x))$
\item $y = \Var(x)^{-1}(x - \E(x))$
\item $y = \Var(x)^{-1/2}(x - \E(x))$
\item $z = (x - \E(x))'\Var(x)(x - \E(x))$
\item $z = (x - \E(x))'\Var(x)^{-1}(x - \E(x))$
\item $z = x'\Var(x)x$
\item $z = x'\Var(x)^{-1}x$
\end{enumerate}
<<echo=FALSE>>=
ex1 <- c(1,4)
varx1 <- matrix(as.integer(c(4,1,1,4)), nrow=2, byrow = FALSE, dimnames = NULL)
@

\item Пусть $y = X\beta + \e$ --- регрессионная модель, где $\beta = \begin{pmatrix} \beta_1 \\ \beta_2 \\ \beta_3 \end{pmatrix}$. Пусть $Z = XD$, где $D = \begin{pmatrix} 1 & 1 & 0 \\ 0 & 1 & 1 \\ 0 & 0 & 1 \end{pmatrix}$. Рассмотрите <<новую>> регрессионную модель $y = Z\alpha + u$, где $\alpha = \begin{pmatrix} \alpha_1 \\ \alpha_2 \\ \alpha_3 \end{pmatrix}$. Определите, как выражаются <<новые>> МНК-коэффициенты через <<старые>>.

<<echo=FALSE,results='asis'>>=
alpha <- matrix(as.integer(c(1,0,0,1,1,0,0,1,1)), nrow=3, byrow = FALSE, dimnames = NULL)
@

\item Пусть $y = X\beta + \e$ --- регрессионная модель, где $\beta = \begin{pmatrix} \beta_1 \\ \beta_2 \\ \beta_3 \end{pmatrix}$. Пусть $Z = XD$, где $D = \begin{pmatrix} 1 & 1 & 1 \\ 0 & 1 & 1 \\ 0 & 0 & 1 \end{pmatrix}$. Рассмотрите <<новую>> регрессионную модель $y = Z\alpha + u$, где $\alpha = \begin{pmatrix} \alpha_1 \\ \alpha_2 \\ \alpha_3 \end{pmatrix}$. Определите, как выражаются <<новые>> МНК-коэффициенты через <<старые>>.

<<echo=FALSE,results='asis'>>=
alpha2 <- matrix(as.integer(c(1,0,0,1,1,0,1,1,1)), nrow=3, ncol=3, byrow = FALSE, dimnames = NULL)
@

\item Пусть $y = X\beta + \e$ --- регрессионная модель, где $\beta = \begin{pmatrix} \beta_1 \\ \beta_2 \\ \beta_3 \end{pmatrix}$. Пусть $Z = XD$, где $D = \begin{pmatrix} 1 & 0 & 0 \\ 0 & 1 & 1 \\ 0 & 0 & 1 \end{pmatrix}$. Рассмотрите <<новую>> регрессионную модель $y = Z\alpha + u$, где $\alpha = \begin{pmatrix} \alpha_1 \\ \alpha_2 \\ \alpha_3 \end{pmatrix}$. Определите, как выражаются <<новые>> МНК-коэффициенты через <<старые>>.

<<echo=FALSE,results='asis'>>=
alpha3 <- matrix(as.integer(c(1,0,0,0,1,0,0,1,1)), nrow=3, ncol=3, byrow = FALSE, dimnames = NULL)
@

\item Пусть $\e = \begin{pmatrix} \e_1 \\ \e_2 \\ \e_3 \end{pmatrix} \sim N (0,\sigma^2 I)$, $i = (1,\dots,1)'$ --- вектор из $n$ единиц, $\pi=i(i'i)^{-1}i'$,
$X$ --- матрица размера ${n \times k}$, $P = X(X'X)^{-1}X'$. Найдите:
\begin{enumerate}
\item $\E(\e'(P - \pi)\e)$ 
\item $\E(\e'(I - \pi)\e)$
\item $\E(\e'P \e)$
\item $\E(\sum_{i=1}^n {(\e_i - \bar{\e})}^2)$
\end{enumerate}

\item Пусть $y = X\beta + \e$ --- регрессионная модель. Верно ли, что $\hat{\e}'\hat{y}=0$ и $\hat{y}'\hat{\e}=0$?
\solution{да, да}

\item Пусть $\e = (\e_1, \e_2, \e_3)'\sim N (0,4I)$, $A = \begin{pmatrix} 4 & 1 & 1 \\ 1 & 3 & 1 \\ 1 & 1 & 2 \end{pmatrix}$. Найдите:

<<echo=FALSE,results='asis'>>=
m_a <- matrix(as.integer(c(4,1,1,1,3,1,1,1,2)), nrow=3, ncol=3, byrow = FALSE, dimnames = NULL)
@

\begin{enumerate}
\item $\E(\e'A\e)$
\item $\E(\e'(I - A)\e)$ 
\end{enumerate}

\item Для нормальной регрессии с 5-ю факторами (включая свободный член) известны границы симметричного по вероятности 80$\%$ доверительного интервала для дисперсии $\sigma_{\e}^2$: $A$ = 45, $B$ = 87.942.

\begin{enumerate}
\item Определите количество наблюдений в выборке
\item Вычислите $\hat{\sigma}_{\e}^2$
\end{enumerate}

\solution{
\begin{enumerate}
\item Поскольку $\frac{\hat{\sigma}_{\e}^2(n-k)}{\sigma_{\e}^2} \sim \chi ^2(n-k)$, где $\hat{\sigma}_{\e}^2 = \frac{RSS}{n-k}$, $k$ = 5. $P(\chi_{l}^2 < \frac{\hat{\sigma}_{\e}^2}{\sigma_{\e}^2} < \chi_{u}^2) = 0.8$. Преобразовав, получим $P(\frac{\hat{\sigma}_{\e}^2(n-5)}{\chi_{u}^2} < \sigma_{\e}^2 < \frac{\hat{\sigma}_{\e}^2(n-5)}{\chi_{l}^2}) = 0.8$, где $\chi_{u}^2 = \chi_{n-5; 0.1} ^2$, $\chi_{l}^2 = \chi_{n-5; 0.9} ^2$ --- соответствующие квантили. По условию $\frac{\hat{\sigma}_{\e}^2(n-5)}{\chi_{l}^2} = A = 45, \frac{\hat{\sigma}_{\e}^2(n-5)}{\chi_{u}^2} = B = 87.942.$ Поделим $B$ на $A$, отсюда следует $\frac{\chi_{u}^2}{\chi_{l}^2} = 1.95426.$ Перебором квантилей в таблице для хи-квадрат распределения мы находим, что $\frac{\chi_{30; 0.1}^2}{\chi_{30; 0.9}^2} = \frac{40.256}{20.599} = 1.95426.$ Значит, $n - 5 = 30$, отсюда следует, что $n = 35.$
\item $\hat{\sigma}_{\e}^2 = 45 \frac{\chi_{u}^2}{n-5} = 45 \frac{40.256}{30} = 60.384$ 
\end{enumerate}
}

\item Пусть $y = X\beta + \e$ --- регрессионная модель, где $\E(\e)=0$, $\Var(\e)=\sigma_{\e}^2 I$. Пусть $A$ --- неслучайная матрица размера $k \times k$, $\det(A) \not= 0.$ Совершается преобразование регрессоров по правилу $Z=XA$. В преобразованных регрессорах уравнение выглядит так: $y = Z\gamma + u$, где $\E(u)=0$, $\Var(u)=\sigma_{u}^2 I.$

\begin{enumerate}
\item Как связаны между собой МНК-оценки $\hat{\beta}$ и $\hat{\gamma}$?
\item Как связаны между собой векторы остатков регрессий?
\item Как связаны между собой прогнозные значения, полученные по двум регрессиям?
\end{enumerate}

\solution{
\begin{enumerate}
\item $\hat{\gamma} = (Z'Z)^{-1}Z'y = A^{-1}(X'X)^{-1}(A')^{-1}A'X'y = A^{-1}(X'X)^{-1} X'y = A^{-1}\hat{\beta}$
\item $\hat{u} = y - Z\hat{\gamma} = y - XAA^{-1}\hat{\beta} = y - X\hat{\beta} = \hat{\e}$
\item Пусть $z^0 = \begin{pmatrix} 1 & z_1^0 & \dots & z_{k-1}^0 \end{pmatrix}$ --- вектор размера $1 \times k$ и $x^0 = \begin{pmatrix} 1 & x_1^0 & \dots & x_{k-1}^0 \end{pmatrix}$ --- вектор размера $1 \times k$. Оба эти вектора представляют собой значения факторов. Тогда $z^0 = x^0 A$ и прогнозное значение для регрессии с преобразованными факторами равно $z^0 \hat{\gamma} = x^0 AA^{-1} \hat{\beta} = x^0 \hat{\beta}$ прогнозному значению для регрессии с исходными факторами. 
\end{enumerate}
}

\item Рассмотрим оценку вида $\tilde{\beta} = ((X'X)^{-1} + \gamma I)X'y$ для вектора коэффициентов регрессионного уравнения $y = X\beta + \e$, удовлетворяющего условиям классической регрессионной модели. Найдите $\E(\tilde{\beta})$ и $\Var(\tilde{\beta}).$ 

\solution{
\begin{enumerate}
\item $\E(\tilde{\beta}) = ((X'X)^{-1} + \gamma I)X'\E(y) = ((X'X)^{-1} + \gamma I)X'X\beta = \beta + \gamma X'X\beta$
\item $\Var(\tilde{\beta}) = \Var(((X'X)^{-1} + \gamma I)X'y) = \Var(((X'X)^{-1} + \gamma I)X'\e) = $

$ = (((X'X)^{-1} + \gamma I)X')\Var(\e)(((X'X)^{-1} + \gamma I)X')'= $

$ = (((X'X)^{-1} + \gamma I)X')\sigma_{\e}^2 I(((X'X)^{-1} + \gamma I)X')'= 
\sigma_{\e}^2((X'X)^{-1} + \gamma I)X'X((X'X)^{-1} + \gamma I) = $

$ = \sigma_{\e}^2((X'X)^{-1} + \gamma I)(I + \gamma X'X) = \sigma_{\e}^2((X'X)^{-1} + 2\gamma I + \gamma ^2 X'X)$
\end{enumerate}
}


\item Верно ли, что при невырожденном преобразовании факторов $R^2$ не меняется? А именно, пусть заданы две регрессионные модели: $y = X\beta + \e$ и $y = Z\alpha + u$, где $y$ --- вектор размера $n \times 1$, $X$ и $Z$ --- матрицы размера $n \times k$, $\beta$ и $\alpha$ --- вектора рамзера $k \times 1$, $\e$ и $u$ --- вектора размера $n \times 1$, а также $Z=XD$, $\det(D) \not= 0.$ Верно ли, что коэффициенты детерминации представленных выше моделей равны между собой?

\item Верно ли, что при невырожденном преобразовании факторов $RSS$ не меняется. А именно, пусть заданы две регрессиионные модели: $y = X\beta + \e$ и $y = Z\alpha + u$, где $y$ --- вектор размера $n \times 1$, $X$ и $Z$ --- матрицы размера $n \times k$, $\beta$ и $\alpha$ --- вектора рамзера $k \times 1$, $\e$ и $u$ --- вектора размера $n \times 1$, а также $Z=XD$, $\det(D) \not= 0.$ Верно ли, что сумма квадратов остатков в представленных выше моделях равны между собой?

\item Пусть $y_i = \beta_1 + \beta_2 x_i + \e_i$ и $i = 1, \dots, 5$ --- классическая регрессионная модель. Также имеются следующие данные: $\sum_{i=1}^5 y_i^2 = 55, \sum_{i=1}^5 x_i^2 = 3, \sum_{i=1}^5 x_iy_i = 12, \sum_{i=1}^5 y_i = 15, \sum_{i=1}^5 x_i = 3.$ Используя их, найдите:

\begin{enumerate}
\item $\hat{\beta_1}$ и $\hat{\beta_2}$
\item $\Corr(\hat{\beta_1}, \hat{\beta_2})$
\item $TSS$
\item $ESS$
\item $RSS$
\item $R^2$
\item $\hat{\sigma}^2$
\end{enumerate}

Проверьте следующие гипотезы:
\begin{enumerate}
\item $\begin{cases}  H_0: \beta_2 = 2  \\ H_a: \beta_2 \not= 2 \end{cases}$
\item $\begin{cases}  H_0: \beta_1 + \beta_2 = 1  \\ H_a: \beta_1 + \beta_2 \not= 1 \end{cases}$
\end{enumerate}

\item Пусть $y_i = \beta_1 + \beta_2 x_i + \e_i$ и $i = 1, \dots, 5$ --- классическая регрессионная модель. Также имеются следующие данные: $\sum_{i=1}^5 y_i^2 = 55, \sum_{i=1}^5 x_i^2 = 2, \sum_{i=1}^5 x_iy_i = 9, \sum_{i=1}^5 y_i = 15, \sum_{i=1}^5 x_i = 2.$ Используя их, найдите:

\begin{enumerate}
\item $\hat{\beta_1}$ и $\hat{\beta_2}$
\item $\Corr(\hat{\beta_1}, \hat{\beta_2})$
\item $TSS$
\item $ESS$
\item $RSS$
\item $R^2$
\item $\hat{\sigma}^2$
\end{enumerate}

Проверьте следующие гипотезы:
\begin{enumerate}
\item $\begin{cases}  H_0: \beta_2 = 2  \\ H_a: \beta_2 \not= 2 \end{cases}$
\item $\begin{cases}  H_0: \beta_1 + \beta_2 = 1  \\ H_a: \beta_1 + \beta_2 \not= 1 \end{cases}$
\end{enumerate}







\end{enumerate}

\end{document}