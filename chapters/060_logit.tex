\Opensolutionfile{solution_file}[solutions/sols_060]
% в квадратных скобках фактическое имя файла



\chapter{Логит и пробит}




\begin{problem}
Случайная величина $X$ имеет логистическое распределение, если её функция плотности имеет вид $f(x)=e^{-x}/(1+e^{-x})^2$.
\begin{enumerate}
\item Является ли $f(x)$ чётной?
\item Постройте график $f(x)$.
\item Найдите функцию распределения, $F(x)$.
\item Найдите $\E(X)$, $\Var(X)$.
\item На какое известный закон распределения похож логистический?
\end{enumerate}


\begin{sol}
$f(x)$ чётная, $\E(X)=0$, $\Var(X)=\pi^2/3$, логистическое похоже на $N(0,\pi^2/3)$
\end{sol}
\end{problem}



\begin{problem}
Логит модель часто формулируют в таком виде:
\[
y_i^*=\beta_1+\beta_2 x_i +\e_i
\]
где $\e_i$ имеет логистическое распределение, и
\[
y_i=\begin{cases}
1,\: y_i^*\geq 0 \\
0,\: y_i^*<0
\end{cases}
\]
\begin{enumerate}
\item Выразите $\P(y_i=1)$ с помощью логистической функции распределения.
\item Найдите $\ln \left(\frac{\P(y_i=1)}{\P(y_i=0)} \right)$.
\end{enumerate}


\begin{sol}
$\ln \left(\frac{\P(y_i=1)}{\P(y_i=0)} \right)=\beta_1+\beta_2 x_i$.
\end{sol}
\end{problem}



\begin{problem}
\useR Сравните на одном графике:
\begin{enumerate}
\item функции плотности логистической и нормальной $\cN(0,\pi^2/3)$ случайных величин;
\item функции распределения логистической и нормальной $\cN(0,\pi^2/3)$ случайных величин.
\end{enumerate}

\begin{sol}
\end{sol}
\end{problem}



\begin{problem}
Как известно, Фрекен Бок любит пить коньяк по утрам. За прошедшие четыре дня она записала, сколько рюмочек коньяка выпила утром, $x_i$, и видела ли она в этот день привидение, $y_i$,

\begin{tabular}{c|ccccc}
\toprule
$y_i$ & 1 & 0 & 1 & 0 & 0 \\
$x_i$ & 2 & 0 & 3 & 3 & 0 \\
\bottomrule
\end{tabular}

Зависимость между $y_i$ и $x_i$ описывается логит-моделью,
\[
\ln
\left(
  \frac{\P(y_i=1)}{\P(y_i=0)}
\right)
=\beta_1+\beta_2 x_i
\]

Предположим корректность использования нормального распределения для оценок правдоподобия.

\begin{enumerate}
\item Выпишите в явном виде логарифмическую функцию максимального правдоподобия.
\item Выпишите условия первого порядка.
\item \useR Найдите оценки параметров $\beta_1$ и $\beta_2$.
\item Разложите функцию правдоподобия в ряд Тейлора до второго порядка в окрестности $\beta_2=0$ и $\beta_1=\Lambda^{-1}(\hat p)$ и найдите примерные оценки $\beta_1$ и $\beta_2$ без компьютера.
\item Найдите оценку ковариационной матрицы оценок коэффициентов.
\item Постройте доверительные интервалы для параметров $\beta_1$ и $\beta_2$.
\item Постройте доверительный интервал для склонности увидеть привидение при трёх выпитых рюмках, $\beta_1 + \beta_2 x_i$.
\item Постройте доверительный интервал для вероятности увидеть привидение при трёх выпитых рюмках двумя способами:
\begin{enumerate}
\item Преобразованием доверительного интервала для склонности
\item С помощью дельта-метода
\end{enumerate}
\item Постройте график зависимости спрогнозированной вероятности увидеть приведение от количества рюмок. Фрекен Бок обладает способностью выпить дробное количество рюмок.
\item Постройте график зависимости предельного эффекта количества рюмок на вероятность увидеть приведение.
\end{enumerate}


\begin{sol}
\end{sol}
\end{problem}



\begin{problem}
При оценке логит модели
\(
\P(y_i=1)=\Lambda(\b_1+\b_2 x_i)
\)
по 500 наблюдениям оказалось, что $\hb_1=0.7$ и $\hb_2=3$. Оценка ковариационной матрицы коэффициентов имеет вид
\[
\begin{pmatrix}
  0.04 & 0.01 \\
  0.01 & 0.09
\end{pmatrix}
\]

\begin{enumerate}
\item Проверьте гипотезу о незначимости коэффициента $\hb_2$.
\item Найдите предельный эффект роста $x_i$ на вероятность $\P(y_i=1)$ при $x_i=-0.5$.
\item Найдите максимальный предельный эффект роста $x_i$ на вероятность $\P(y_i=1)$.
\item Постройте точечный прогноз вероятности $\P(y_i=1)$ если $x_i = -0.5$.
\item Найдите стандартную ошибку построенного прогноза.
\item Постройте 95\%-ый доверительный интервал для $\P(y_i=1)$ двумя способами (через преобразование интервала для $\hy_i^*$ и через дельта-метод).
\end{enumerate}
\begin{sol}
$z = \frac{\hb_2}{se(\hb_2)}=\frac{3}{0.3}=10$, $H_0$ отвергается.
Предельный эффект равен $\hb_2 \Lambda'(-0.8)\approx 0.642$.
Для нахождения $se(\hat\P)$ найдём линейную аппроксимацию для $\Lambda(\hb_1 + \hb_2 x)$ в окрестности точки $\hb_1=0.7$, $\hb_2=3$. Получаем
\[
\Lambda(\hb_1 + \hb_2 x) \approx \Lambda(\beta_1 + \beta_2 x) + \Lambda'(\beta_1 + \beta_2 x) (\hb_1 - \beta_1) + \Lambda'(\beta_1 + \beta_2 x)x(\hb_2 - \beta_2).
\]
\end{sol}
\end{problem}



\begin{problem}
Винни-Пух знает, что мёд бывает правильный, $honey_i=1$, и неправильный, $honey_i=0$. Пчёлы также бывают правильные, $bee_i=1$, и неправильные, $bee_i=0$. По 100 своим попыткам добыть мёд Винни-Пух составил таблицу сопряженности:

\begin{tabular}{c|cc}
\toprule
 & $honey_i=1$ & $honey_i=0$ \\
\midrule
$bee_i=1$ & 12 & 36 \\
$bee_i=0$ & 32 & 20 \\
\bottomrule
\end{tabular}

Используя метод максимального правдоподобия Винни-Пух хочет оценить логит-модель для прогнозирования правильности мёда с помощью правильности пчёл:
\[
\ln \left(\frac{\P(honey_i=1)}{\P(honey_i=0)} \right)=\beta_1 + \beta_2 bee_i
\]
\begin{enumerate}
\item Выпишите функцию правдоподобия для оценки параметров $\beta_1$ и $\beta_2$.
\item Оцените неизвестные параметры.
\item С помощью теста отношения правдоподобия проверьте гипотезу о том, правильность пчёл не связана с правильностью мёда на уровне значимости 5\%.
\item Держась в небе за воздушный шарик, Винни-Пух неожиданно понял, что перед ним неправильные пчёлы. Помогите ему оценить вероятность того, что они делают неправильный мёд.
\end{enumerate}


\begin{sol}
Для краткости введем следующие обозначения: $y_i = honey_i$, $d_i = bee_i$\footnote{$Y_i$ — случайный Мёд, $y_i$ — реализация случайного Мёда (наблюдаемый Мёд)}.

\begin{enumerate}
\item Функция правдоподобия имеет следующий вид:

\begin{multline*}
\text{L}(\beta_1, \beta_2) = \prod_{i=1}^n \P_{\beta_1, \beta_2} \left(\left\lbrace Y_i = y_i \right\rbrace \right) =\\
 \prod_{i: y_i = 0} \P_{\beta_1, \beta_2} \left(\left\lbrace Y_i = 1 \right\rbrace \right) \cdot \prod_{i: y_i = 1} \P_{\beta_1, \beta_2} \left(\left\lbrace Y_i = 0 \right\rbrace \right) =\\
\prod_{i: y_i = 1} \Lambda(\beta_1 + \beta_2 d_i) \cdot \prod_{i: y_i = 0} [1 - \Lambda(\beta_1 + \beta_2 d_i)] = \\
\prod_{i: y_i = 1, d_i = 1} \Lambda(\beta_1 + \beta_2) \cdot \prod_{i: y_i = 1, d_i = 0} \Lambda(\beta_1) \cdot \prod_{i: y_i = 0, d_i = 1} [1 - \Lambda(\beta_1 + \beta_2)] \cdot \\
\cdot \prod_{i: y_i = 0, d_i = 0} [1 - \Lambda(\beta_1)] = \\
\Lambda(\beta_1 + \beta_2)^{\#\{i: y_i=1, d_i=1\}} \cdot \Lambda(\beta_1)^{\#\{i: y_i=1, d_i=0\}} \cdot [1 - \Lambda(\beta_1 + \beta_2)]^{\#\{i: y_i=0, d_i=1\}} \cdot \\
\cdot  [1 - \Lambda(\beta_1)]^{\#\{i: y_i=0, d_i=0\}}
\end{multline*}
где
\[
\Lambda(x) = \frac{e^x}{1 + e^x}
\]
логистическая функция распределения, $\#A$ означает число элементов множества $A$.

\item Введём следующие обозначения:
\[
a = \Lambda(\beta_1)
\]
\[
b = \Lambda(\beta_1 + \beta_2)
\]



Тогда с учетом имеющихся наблюдений функция правдоподобия принимает вид:

\[
\text{L}(a, b) = b^{12} \cdot a^{32} \cdot (1 - b)^{36} \cdot (1 - a)^{20}
\]

Логарифмическая функция правдоподобия:

\[
\ell(a, b) = \ln \text{L}(a, b) = 12\ln b + 32\ln a + 36\ln(1-b) + 20\ln(1 - a)
\]

Решая систему уравнений правдоподобия

\[
\begin{cases}
\frac{\partial \ell}{\partial a} = \frac{32}{a} - \frac{20}{1 - a} = 0 \\
\frac{\partial \ell}{\partial b} = \frac{12}{b} - \frac{36}{1 - b} = 0 \\
\end{cases}
\]
получаем $\hat{a} = \frac{8}{13}$, $\hat{b} = \frac{1}{4}$. Находим $\hb_{1, UR} = \ln\left( \frac{\hat{a}}{1 - \hat{a}} \right)= \ln \left(\frac{8}{5} \right) = 0.47$. Далее получаем, что $\hb_{1, UR} + \hb_{2, UR} = \ln \left( \frac{\hat{b}}{1 - \hat{b}} \right)$. Следовательно, $\hb_{2, UR} = \ln \left( \frac{\hat{b}}{1 - \hat{b}} \right) - \hb_{1, UR} = \ln \left( \frac{1}{3} \right) - \ln \left( \frac{8}{5} \right) = -1.57$.

\item Гипотеза, состоящая в том, что правильность Мёда не связана с правильностью
пчёл, формализуется как $H_0: \beta_2 = 0$. Протестируем данную гипотезу при помощи теста
отношения правдоподобия. Положим в функции правдоподобия $\text{L}(\beta_1, \beta_2)$ $\beta_2 = 0$. Тогда получим
\[
\text{L}(a, b=a) = a^{32+12} \cdot (1-a)^{20+36}
\]
В этом случае логарифмическая функция правдоподобия имеет вид:
\[
\ell(a, b=a) := \text{L}(a, b=a) = 44 \ln a + 56 \ln(1-a)
\]
Решаем уравнение правдоподобия
\[
\frac{\partial \ell}{\partial a} = \frac{44}{a} - \frac{56}{1 - a} = 0
\]
и получаем $\hat{a} = \frac{11}{25}$. Следовательно, $\hb_{1, R} = -0.24$ и $\hb_{2, R} = 0$.

Статистика отношения правдоподобия имеет вид:
\[
LR = -2(\ell(\hb_{1, R}, \hb_{2, R}) - \ell(\hb_{1, UR}, \hb_{2, UR}))
\]
и имеет асимптотическое $\chi^2$ распределение с числом степеней свободы, равным числу ограничений, составляющих гипотезу $H_0$, то есть в данном случае $LR \overset{a}{\sim} \chi^2_1$.

Находим наблюдаемое значение статистики отношения правдоподобия:
\begin{multline*}
\ell(\hb_{1, R}, \hb_{2, R}) = \ell(\hat{a}_R, \hat{b}_R = \hat{a}_R) = 44\ln\hat{a}_R + 56\ln[1-\hat{a}_R] =\\
 44\ln \left[ \frac{11}{25} \right] + 56\ln \left[ 1 - \frac{11}{25} \right] = -68.59
\end{multline*}
\begin{multline*}
\ell(\hb_{1, UR}, \hb_{2, UR}) = \ell(\hat{a}_{UR}, \hat{b}_{UR}) =\\
 12\ln \hat{b}_{UR} + 32 \ln \hat{a}_{UR} + 36\ln[1 - \hat{b}_{UR}] + 20\ln[1 - \hat{a}_{UR}] = \\
12\ln \left[ \frac{1}{4} \right] + 32\ln \left[ \frac{8}{13} \right] + 36\ln \left[ 1 - \frac{1}{4} \right] + 20\ln \left[1 - \frac{8}{13} \right] = -61.63
\end{multline*}
Следовательно, $LR = -2(-68.59 + 61.63) = 13.92$, при этом критическое значение $\chi^2$ распределения с одной степенью свободы для 5\% уровня значимости равна 3.84. Значит, на основании теста отношения правдоподобия гипотеза $H_0: \beta_2 = 0$ должна быть отвергнута. Таким образом, данные показывают, что, в действительности, правильность мёда связана с правильностью пчёл.

\item
\begin{multline*}
\hat{\P}\{honey = 0| bee = 0\} = 1 - \hat{\P}\{honey=1|bee=0\} = \\
1 - \frac{\exp\{\hb_{1, UR} + \hb_{2, UR} \cdot 0\}}{1 + \exp\{\hb_{1, UR} + \hb_{2, UR} \cdot 0\}} =\\
1 - \frac{\exp\{\ln\left( \frac{8}{5} \right)\}}{1 + \exp\{\ln\left( \frac{8}{5} \right)\}} = 1 - 0.62 = 0.38
\end{multline*}
\end{enumerate}
\end{sol}
\end{problem}



\begin{problem}
Имеются следующие наблюдения

\begin{tabular}{c|ccc}
\toprule
$y_i$ & 1 & 0 & 0 \\
$x_i$ & 1 & 2 & 3 \\
\bottomrule
\end{tabular}

Предположим, что логит модель верна.

\begin{enumerate}
\item Существуют ли оценки метода максимального правдоподобия?
\item Что произойдёт, если попробовать оценить эту модель в R?
\item Спасёт ли ситуацию рассмотрение пробит-модели?
\item В рамках байесовского подхода найдите среднее апостериорного распределения коэффициентов при априорном предположении $\beta_1 \sim \cN(0, 100^2)$, $\beta_2 \sim \cN(0, 100^2)$ и их независимости.
\end{enumerate}



\begin{sol}
в теории оценки не существуют, в R получатся некие точечные оценки, достаточно далеко лежащие от нуля с огромными стандартными ошибками и $P$-значением близким к 1.
\end{sol}
\end{problem}



\begin{problem}
Из имеющихся 100 наблюдений $y_i$ — 70 единиц и 30 нулей. Александр Македонский оценил логит-модель $\P(y_i=1)=\P(y_i^*>0)$, $y_i^*=\beta_1 + \beta_2 x_i + \e_i$.  Затем Александр построил прогнозы $\hat{p}_i$. Чему равна сумма прогнозных значений $\sum_{i=1}^n \hat{p}_i$?


\begin{sol}
Из условий первого порядка для метода максимального правдоподобия следует, что $\sum_{i=1}^n y_i = \sum_{i=1}^n \hat{p}_i=70$.
\end{sol}
\end{problem}

\begin{problem}
Опишите логит-модель упорядоченного выбора. Выведите выражения для предельных эффектов.
\begin{sol}
\end{sol}
\end{problem}


\begin{problem}
Приведите пример небольшого набора данных для которого оценки логит модели $\P(y_i=1)=F(\beta_1 + \beta_2 x_i)$ не существуют. В наборе данных должны присутствовать хотя бы одно наблюдение $y_i=0$ и хотя бы одно наблюдение $y_i=1$.
\begin{sol}
\end{sol}
\end{problem}

\begin{problem}
Почему в пробит-модели предполагается, что $\e_i \sim \cN(0;1)$, а не $\e_i \sim \cN(0;\sigma^2)$ как в линейной регрессии?
\begin{sol}
Если в пробит-уравнении ненаблюдаемой переменной домножить все коэффициенты и стандартную ошибку на произвольную константу, то в результате получится ровно та же модель. Следовательно, модель с $\e_i \sim \cN(0;\sigma^2)$ не идентифицируема. Поэтому надо взять какое-то нормировочное условие. Можно взять, например, $\beta_2 = 42$, но традиционно берут $\e_i \sim \cN(0;1)$.
\end{sol}
\end{problem}


\begin{problem}
Методом максимального правдоподобия оценили логит-модель $\hy^*_i=2+3x_i - 5z_i$
\begin{enumerate}
\item Оцените вероятность того, что $y_i=1$ для $\bar{x}=5$, $\bar{z}=3.5$.
\item Оцените предельный эффект увеличения $x$ на единицу на вероятность того, что $y_i=1$ для $\bar{x}=5$, $\bar{z}=3.5$.
\item При каком значении $x$ предельный эффект увеличения $z$ на 1 в точке $\bar{z}=3.5$ будет максимальным?
\end{enumerate}

\begin{sol}
Предельный эффект максимален при $x=31/6$, достигается он при максимальной производной $\Lambda'(\hat \beta_1 + \hat\beta_2x + \hat\beta_3z)$, то есть при $\hat \beta_1 + \hat\beta_2x + \hat\beta_3z=0$.
\end{sol}
\end{problem}



\begin{problem}
Что произойдёт с оценками логит-модели $\P(y_i=1)=F(\beta_1 + \beta_2 x_i)$, их стандартными ошибками, если у зависимой переменной поменять $0$ и $1$ местами?
\begin{sol}
\end{sol}
\end{problem}




\begin{problem}
Установите и подключите пакет \verb|Ecdat|. Активируйте встроенный набор данных по посещениям врача \verb|Doctor| и введите бинарную переменную \verb|y|, для тех семей, у которых был хотя бы один визит.


\begin{enumerate}
\item Постройте логит модель для переменной $y$, в качестве объясняющих выберите переменные $children$, $access$ и $health$. Постройте 90\% доверительный интервал для коэффициента при количестве детей.

\item Оцените предельный эффект от увеличения количества детей на одного для среднестатистической семьи.

\item Постройте 90\%-ый предиктивный интервал для вероятности посетить доктора для семьи в которой 2 ребенка, $health=0$ и $access=0.5$.
\end{enumerate}

\begin{sol}
\begin{minted}[mathescape, numbersep=5pt, frame=lines, framesep=2mm]{r}
data <- mutate(Ecdat::Doctor, y = ifelse(1, 0, doctor > 0))
\end{minted}

\end{sol}
\end{problem}


\Closesolutionfile{solution_file}
