\Opensolutionfile{solution_file}[sols_070]
% в квадратных скобках фактическое имя файла

\chapter{Мультиколлинеарность}


\begin{problem}
Сгенерируйте данные так, чтобы при оценке модели $\hat{y}=\hat{\beta_1}+\hat{\beta_2}x+\hat{\beta_3}z$ оказывалось, что по отдельности оценки коэффициентов $\hat{\beta_2}$ и $\hat{\beta_3}$ незначимы, но модель в целом --- значима.

\begin{sol}
\end{sol}
\end{problem}


\begin{problem}
В этом задании нужно сгенерировать зависимую переменную $y$ и два регрессора $x$ и $z$.
\begin{enumerate}
\item Сгенерируйте данные так, чтобы корреляция между регрессорами $x$ и $z$ была больше $0.9$, и проблема мультиколлинеарности есть, т.е. по отдельности регрессоры не значимы, но регрессия в целом --- значима.
\item А теперь сгенерируйте данные так, чтобы корреляция между регрессорами была по-прежнему больше $0.9$, но проблемы мультиколлинеарности бы не было, т.е. все коэффициенты были бы значимы.
\item Есть несколько способов, как изменить генерации случайных величин, чтобы перейти от ситуации <<a>> к ситуации <<b>>. Назовите хотя бы два.
\end{enumerate}

\begin{sol}
увеличить количество наблюдений, уменьшить дисперсию случайной ошибки
\end{sol}
\end{problem}



\begin{problem}
Исследуем зависимость длины тормозного пути автомобиля от скорости по историческим данным 1920-х годов.

<<message=FALSE>>=
h <- cars
ggplot(h,aes(x=speed,y=dist))+geom_point()+
    labs(title="Зависимость длины тормозного пути",
    x="Скорость, миль в час",y="Длина пути, футов")
speed.mean <- mean(h$speed)
@

Построим результаты оценивания нецентрированной регрессии:
<<>>=
cars.model <- lm(dist~speed+I(speed^2)+I(speed^3),data=h)
cars.table <- as.table(coeftest(cars.model))
rownames(cars.table) <-
  c("Константа","speed","speed^2","speed^3")
@

%\todo[inline]{с тремя переменными руками громоздко делать, а с двумя вроде не видно мультик.}

<<results='asis'>>=
xtable(cars.table)
@

Ковариационная матрица коэффициентов имеет вид:
<<results='asis'>>=
cars.vcov <- vcov(cars.model)
rownames(cars.vcov) <-
  c("Константа","speed","speed^2","speed^3")
colnames(cars.vcov) <-
  c("Константа","speed","speed^2","speed^3")
xtable(cars.vcov)
@

\begin{enumerate}
\item Проверьте значимость всех коэффициентов и регрессии в целом
\item Постройте 95\%-ый доверительный интервал для $\E(dist)$ при $speed=10$
\item Постройте 95\%-ый доверительный интервал для $\E(ddist/dspeed)$ при $speed=10$
\item Как выглядит уравнение регрессии, если вместо $speed$ использовать центрированную скорость? Известно, что средняя скорость равна $\Sexpr{speed.mean}$
\item С помощью регрессии с центрированной скоростью ответьте на предыдущие вопросы.
\end{enumerate}


\begin{sol}
\end{sol}
\end{problem}



\begin{problem}
Пионеры, Крокодил Гена и Чебурашка собирали металлолом несколько дней подряд. В распоряжение иностранной шпионки, гражданки Шапокляк, попали ежедневные данные по количеству собранного металлолома: вектор $g$ --- для Крокодила Гены, вектор $h$ --- для Чебурашки и вектор $x$ --- для Пионеров. Гена и Чебурашка собирали вместе, поэтому выборочная корреляция $\sCorr(g,h)=-0.9$. Гена и Чебурашка собирали независимо от Пионеров, поэтому выборочные корреляции $\sCorr(g,x)=0$, $\sCorr(h,x)=0$. Если регрессоры $g$, $h$ и $x$ центрировать и нормировать, то получится матрица $\tilde{X}$.
\begin{enumerate}
\item Найдите параметр обусловленности матрицы $(\tilde{X}'\tilde{X})$
\item Вычислите одну или две главные компоненты (выразите их через вектор-столбцы матрицы $\tilde{X}$), объясняющие не менее 70\% общей выборочной дисперсии регрессоров
\item Шпионка Шапокляк пытается смоделировать ежедневный выпуск танков, $y$. Выразите оценки коэффициентов регрессии $y = \beta_1 + \beta_2 g +\beta_3 h +\beta_4 x+\varepsilon$ через оценки коэффициентов регрессии на главные компоненты, объясняющие не менее 70\% общей выборочной дисперсии.
\end{enumerate}

\begin{sol}
\end{sol}
\end{problem}




\begin{problem}
Для модели $y_i=\beta x_i+\e$ рассмотрите модель Ridge regression с коэффициентом $\lambda$.
\begin{enumerate}
\item Выведите формулу для $\hb_{RR}$
\item Найдите $\E(\hb_{RR})$, смещение оценки $\hb_{RR}$,
\item Найдите $\Var(\hb_{RR})$, $MSE(\hb_{RR})$
\item Всегда ли оценка $\hb_{RR}$ смещена?
\item Всегда ли оценка $\hb_{RR}$ имеет меньшую дисперсию, чем $\hb_{ols}$?
\item Найдите такое $\lambda$, что $MSE(\hb_{RR})<MSE(\hb_{ols})$
\end{enumerate}

\begin{sol}
\end{sol}
\end{problem}




\begin{problem}
Известно, что в модели $y=X\beta+\e$ все регрессоры ортогональны.
\begin{enumerate}
\item Как выглядит матрица $X'X$ в случае ортогональных регрессоров?
\item Выведите $\hb_{rr}$ в явном виде
\item Как связаны между собой $\hb_{rr}$ и $\hb_{ols}$?
\end{enumerate}

\begin{sol}
\end{sol}
\end{problem}



\begin{problem}
Для модели $y_i=\beta x_i + \e_i$ выведите в явном виде $\hb_{lasso}$.

\begin{sol}
\end{sol}
\end{problem}



\begin{problem}
Предположим, что для модели $y_i= \beta_1 + \beta_2 x_{i2} + \beta_3 x_{i3} + \beta_4 x_{i4}  + \e_i$ выборочная корреляционная матрица регрессоров $x_2$, $x_3$, $x_4$ имеет вид

\[
C =
\begin{pmatrix}
1 & r & r  \\
r & 1 & r  \\
r & r & 1
\end{pmatrix}
\]


\begin{enumerate}
\item Найдите такое значение $r^* \in (-1;1)$ коэффициента корреляции, при котором $\det C = 0$.
\item Найдите собственные значения и собственные векторы матрицы $C$ при корреляции равной найденному $r^*$.
\item Найдите число обусловленности матрицы $C$ при корреляции равной найденному $r^*$.
\item Сделайте вывод о наличии мультиколлинеарности в модели при корреляции равной найденному $r^*$.
\end{enumerate}


\begin{sol}
$r^* = -1/2$
\end{sol}
\end{problem}





\begin{problem}
Предположим, что для модели $y_i= \beta_1 + \beta_2 x_{i2} + \beta_3 x_{i3} + \beta_4 x_{i4} + \beta_5 x_{i5} + \e_i$ выборочная корреляционная матрица регрессоров $x_2$, $x_3$, $x_4$ и $x_5$ имеет вид

\[
C =
\begin{pmatrix}
1 & r & r & r \\
r & 1 & r & r \\
r & r & 1 & r \\
r & r & r & 1
\end{pmatrix}
\]


\begin{enumerate}
\item Найдите такое значение $r^* \in (-1;1)$ коэффициента корреляции, при котором $\det C = 0$.
\item Найдите собственные значения и собственные векторы матрицы $C$ при корреляции равной найденному $r^*$.
\item Найдите число обусловленности матрицы $C$ при корреляции равной найденному $r^*$.
\item Сделайте вывод о наличии мультиколлинеарности в модели при корреляции равной найденному $r^*$.
\end{enumerate}


\begin{sol}
$r^* = -1/3$
\end{sol}
\end{problem}


\begin{problem}
Эконометресса Фатима оценивает модель $y_i=\beta_1 +\beta_2 x_i + \beta_3 z_i + \e_i$. Известно, что $\e_i \sim N(0,76)$. Про регрессоры известно, что $\sum (x_i-\bar{x})^2=10$, $\sum (z_i-\bar{z})^2=20$, а выборочная корреляция между ними равна $sCorr(x,z)=0.9$.

Найдите $\Var(\hb_2)$, $\Var(\hb_3)$


\begin{sol}
$\Var(\hb_2)=\frac{\sigma^2}{RSS_2}=40$, $\Var(\hb_3)=\frac{\sigma^2}{RSS_3}=20$, а $RSS_j=(1-R^2_j) \cdot TSS_j$. При этом в парной регрессии $x$ на $z$ или $z$ на $x$ коэффициенты $R^2$ равны и равны квадрату выборочной корреляции, то есть $R^2_j=0.81$.
\end{sol}
\end{problem}


\begin{problem}
Эконометресса Алевтина перешла от исходных регрессоров к трём главным компонентам, $z_1$, $z_2$ и $z_3$. И далее посчитала коэффициенты вздутия дисперсии, $VIF_j$, для главных компонент. Чему они оказались равны?


\begin{sol}
$1$, т.к. все главные компоненты ортогональны
\end{sol}
\end{problem}



\begin{problem}
С помощью трёх-кратной кросс-валидации выберите наилучшее из двух $\lambda$, $1$ или $10$, в гребневой регрессии $y_i=\beta x_i + \e_i$:
\begin{tabular}{|c|c|}
$y_i$ & $x_i$ \\
\hline
1 & 1 \\
5 & 1 \\
5 & 2 \\
\end{tabular}


\begin{sol}

\end{sol}
\end{problem}



\begin{problem}
Известно, что выборочная корреляция между переменными $x$ и $z$ равна $0.9$.
\begin{enumerate}
\item Найдите коэффициенты VIF для $x$ и $z$ в регрессии $y_i=\beta_1 + \beta_2 x_i + \beta_3 z_i + \e_i$
\item В каких пределах могут лежать коэффициенты VIF для $x$ и $z$ в регрессии $y_i=\beta_1 + \beta_2 x_i + \beta_3 z_i + \beta_4 w_i + \e_i$?
\end{enumerate}


\begin{sol}
$VIF=1/0.19$, $VIF\geq 1/0.19$
\end{sol}
\end{problem}


\begin{problem}
Эконометресса Мишель построила регрессию, затем рассчитала прогноз и построила 90\%-ый предиктивный интервал. И после этого с ужасом обнаружила, что в данных есть мультиколлинеарность. Тогда Мишель с целью уменьшения дисперсии прогнозов решила перейти к ортогональным переменным. Вместо трёх исходных регрессоров Мишель использовала три главных компоненты в новой регрессии.

\begin{enumerate}
\item Как изменятся прогнозы?
\item Как изменится 90\%-ый предиктивный интервал?
\end{enumerate}


\begin{sol}
Никак, Мишель сделала линейную замену регрессоров, $\tilde X = X \cdot A$, где $A$ --- обратима.
\end{sol}
\end{problem}



\Closesolutionfile{solution_file}
