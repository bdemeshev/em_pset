\Opensolutionfile{solution_file}[sols_100]
% в квадратных скобках фактическое имя файла

\chapter{Метод инструментальных переменных}



Экзогенность, $\E(\e\mid x)=0$

Предопределённость, $\E(\e_t\mid x_t)=0$ для всех $t$



\begin{problem}
Настоящая зависимость между $y_i$ и $x_i$ имеет вид $y_i=\beta x_i +\e_i$, где $\e_i$ независимы и равновероятно принимают значения $-1$ и $+1$. Эконометресса Аврора оценивает коэффициент $\beta$ по двум наблюдениям. Аврора не знает чему равны настоящие $x_i$, вместо них она наблюдает значения $x^*_i=x_i+u_i$, где $u_i$ — ошибки измерения, поэтому она строит регрессию $y_i$ на $x_i^*$. Ошибки измерения регрессора, $u_i$, независимы и равновероятно принимают значения $-1$ и $+1$. Величины $u_i$ и $\e_j$ независимы.
\begin{enumerate}
\item Выведите явную формулу для оценки $\hb$
\item Чему равно $u_i^2$? Чему равно $\e_i^2$?
\item Найдите $\E(\hb)$, если $x_1=0$ и $x_2=1$
\item Найдите $\E(\hb)$, если $x_1=0$ и $x_2=2$
\item Интуитивно объясните, как меняется смещение с ростом расстояния между $x_1$ и $x_2$
\end{enumerate}


\begin{sol}
Замечаем, что $u_i^2=\e_i^2=1$. Считаем:
\[
\E(\hb \mid x_1, x_2) = \E\left( \frac{x_1^*}{(x_1^*)^2  + (x_2^*)^2}\right) \E(y_1) + \E\left( \frac{x_2^*}{(x_1^*)^2  + (x_2^*)^2}\right) \E(y_2)
\]

В обоих случаях $\E(y_1)=0$. Получаем, $\E(\hb \mid x_1=0, \, x_2=1)=0.2\beta$, $\E(\hb \mid x_1=0, \, x_2=2)=0.8\beta$. Интуитивно объясняем: рисуем прямую по двум точкам. Мы знаем абсциссы точек с точностью $\pm 1$. Если точки близки, то это может сильно менять оценку наклона, если точки далеки, то случайность слабо влияет на наклон.
\end{sol}
\end{problem}


\begin{problem}
Известна совместная функция плотности пары величин $X_i$, $Y_i$
\[
f(x,y)=
\begin{cases}
x+y, \; x\in[0;1], \; y\in [0;1] \\
0, \; \text{иначе}
\end{cases}
\]
Найдитe
\begin{enumerate}
\item $\E(X_i)$, $\E(Y_i)$, $\Var(X_i)$, $\Var(Y_i)$, $\Cov(X_i,Y_i)$
\item $\E(Y_i \mid X_i)$, $\E(X_i \mid Y_i)$
\item Вася оценивает модель $y_i=\beta_1+\beta_2 x_i+\e_i$ по огромному количеству наблюдений, $n>>0$. Чему примерно у него окажутся равны $\hb_1$, $\hb_2$, $\hs^2$, $\widehat{\Var}(\hb_2)$? Чему равно $\E(\hb_2)$?
%\item Петя оцениваем модель $y_i=\beta_1+\beta_2 x_i+\beta_2 x_i^2+\e_i$. Найдите $\E(\hb_1)$, $\E(\hb_2)$, $\E(\hb_3)$, $\Var(\hb)$ (?)
\end{enumerate}


\begin{sol}
\end{sol}
\end{problem}


\begin{problem}
Задан совместный закон распределения случайных величин $x$ и $\e$:

\begin{tabular}{c|cccc}
 & $\e=-2$ & $\e=-1$ & $\e=1$ & $\e=-2$ \\
\hline
$x=1$ & 0.2 & 0.3 & 0 & 0 \\
$x=2$ & 0 & 0 & 0.3 & 0.2 \\
\end{tabular}

Найдите $\E(\varepsilon)$, $\E(\varepsilon \mid x)$, $\Cov(\varepsilon,x)$, $\Cov(\varepsilon,x|x)$


\begin{sol}
\end{sol}
\end{problem}


\begin{problem}
Приведите примеры дискретных случайных величин $\e$ и $x$, таких, что
\begin{enumerate}
\item $\E(\e)=0$, $\E(\e\mid x)=0$, но величины зависимы. Чему в этом случае равно $\Cov(\e,x)$?
\item $\E(\e)=0$, $\Cov(\e,x)=0$, но $\E(\e\mid x)\neq 0$. Зависимы ли эти случайные величины?
\end{enumerate}


\begin{sol}
\end{sol}
\end{problem}



\begin{problem}
Эконометресса Агнесса хочет оценить модель $y_i=\beta_1+\beta_2 x_i +\e_i$, но, к сожалению, величина $x_i$ ненаблюдаема. Вместо неё доступна величина  $x_i^*$. Величина $x_i^*$  содержит ошибку измерения, $x_i^*=x_i+a_i$. Известно, что $\Var(x_i)=9$, $\Var(a_i)=4$,   $\Var(\e_i)=1$. Величины $x_i$, $a_i$ и $\e_i$ независимы.

Агнесса оценивает регрессию $\hy_i=\hb_1+\hb_2 x_i^*$ с помощью МНК.
\begin{enumerate}
\item Найдите $\plim \hb_2$
\item Являются ли оценки, получаемые Агнессой, состоятельными?
\end{enumerate}


\begin{sol}
\end{sol}
\end{problem}



\begin{problem}
ошибка измерения и коррелированная инструментальная ?


\begin{sol}
\end{sol}
\end{problem}



\begin{problem}
Эконометресса Анжелла хочет оценить модель $y_i=\beta_1+\beta_2 x_i +\beta_3 w_i +\e_i$, но, к сожалению, величина $w_i$ ненаблюдаема. Известно, что $\Var(x_i)=9$, $\Var(w_i)=4$,  $\Var(\e_i)=1$ и $\Cov(x_i,w_i)=-2$. Случайная составляющая не коррелированна с регрессорами.

За неимением $w_i$ Анжелла оценивает регрессию $\hy_i=\hb_1+\hb_2 x_i$ с помощью МНК.
\begin{enumerate}
\item Найдите $\plim \hb_2$
\item Являются ли оценки, получаемые Агнессой, состоятельными?
\end{enumerate}

%Анжелла сумела найти переменную $z_i$, такую что $\Cov(z_i,\e_i)=0$ $\Cov(z_i,


\begin{sol}
\end{sol}
\end{problem}




\begin{problem}
Насяльника хочет оценить модель $y_i=\beta_1+\beta_2 x_i +\e_i$, к сожалению, величина $x_i$ ненаблюдаема. Вместо неё доступны  $x_i^a$, померянный Равшаном, и $x_i^b$, померянный Джумшутом. Естественно, $x_i^a$ и $x_i^b$ содержат ошибку измерения, $x_i^a=x_i+a_i$, $x_i^b=x_i+b_i$. Известно, что $\Var(x_i)=\sigma^2_x$, $\Var(a_i)=\sigma^2_a$,  $\Var(b_i)=\sigma^2_b$,  $\Var(\e_i)=\sigma^2_{\e}$. Величины $x_i$, $a_i$, $b_i$ и $\e_i$ независимы.

\begin{enumerate}
\item Найдите асимптотическое смещение оценки $\hb_2$ для следующих случаев:
\begin{enumerate}
\item С помощью МНК оценивается модель $\hy_i=\hb_1+\hb_2 x_i^a$
\item С помощью МНК оценивается модель $\hy_i=\hb_1+\hb_2 x_i^b$
\item С помощью МНК оценивается модель $\hy_i=\hb_1+\hb_2 \frac{x_i^a+x_i^b}{2}$
\item Методом инструментальных переменных оценивается модель $\hy_i=\hb_1+\hb_2 x_i^a$, в роли инструмента выступает $x_i^b$
\item Методом инструментальных переменных оценивается модель $\hy_i=\hb_1+\hb_2 x_i^b$, в роли инструмента выступает $x_i^a$
\end{enumerate}
\item Какой из методов даёт наибольшее смещение? Наименьшее смещение?
\item Какой из вариантов применения инструментальных переменных предпочтительнее с точки зрения дисперсии получаемой оценки $\hb_2$?
\end{enumerate}




\begin{problem}
Наблюдения представляют собой случайную выборку. Известна истинная ковариационная матрица и математическое ожидание:
\[
\Var
\begin{pmatrix}
x_i \\
y_i
\end{pmatrix}
=
\begin{pmatrix}
9 & 1 \\
1 & 16
\end{pmatrix}, \;
\E\begin{pmatrix}
x_i \\
y_i
\end{pmatrix}
=
\begin{pmatrix}
2 \\
-3
\end{pmatrix}
\]

\begin{enumerate}
\item Найдите $\plim \hb_1$ и $\plim \hb_2$ в регрессии $\hy_i = \hb_1 + \hb_2 x_i$
\item Найдите $\plim \hb_1$ и $\plim \hb_2$ в регрессии $\hat x_i = \hb_1 + \hb_2 y_i$
\end{enumerate}




\begin{sol}
\end{sol}
\end{problem}



\begin{sol}
\end{sol}
\end{problem}


\begin{problem}
Наблюдения представляют собой случайную выборку. Известна истинная ковариационная матрица:
\[
\Var
\begin{pmatrix}
x_i \\
y_i \\
z_i
\end{pmatrix}
 =
\begin{pmatrix}
9 & 1 & 2 \\
1 & 16 & -1 \\
2 & -1 & 25
\end{pmatrix}
\]

\begin{enumerate}
\item Найдите $\plim \hb_2$ в модели $\hy_i = \hb_1 + \hb_2 z_i$
\item Найдите $\plim \hat \mu_2$ в модели $\hat x_i = \hat \mu_1 + \hat \mu_2 z_i$
\item Найдите $\plim \hat \gamma_2$ в модели $\hy_i = \hat \gamma_1 + \hat \gamma_2 x_i + \hat \gamma_3 z_i $
\end{enumerate}

\begin{sol}
\end{sol}
\end{problem}


\begin{problem}
Рассмотрим классическую линейную регрессионную модель:
\[
y_i = \b_1 + \b_2 x_i + \b_3 z_i + \e_i
\]

\begin{enumerate}
\item Огюст Люмьер утверждает, что при нестохастических регрессорах математические ожидания $\E(y_i)$ различны. Луи Люмьер утверждает, что при стохастических регрессорах и предпосылке о том, что наблюдения являются случайной выборкой, все $\E(y_i)$ равны между собой. Кто из них прав?
\item Помогите Луи Люмьеру найти $\plim \he_1$ и $\plim \hy_1$
\end{enumerate}

\begin{sol}
Оба правы, $\plim \he_1 = \e_1$ и $\plim \hy_1= \b_1 + \b_2 x_i + \b_3 z_i$
\end{sol}
\end{problem}


\begin{problem}
Рассмотрим классическую линейную регрессионную модель:
\[
y_i = \b_1 + \b_2 x_i + \b_3 z_i + \e_i
\]

Наблюдения является случайной выборкой. Истинная ковариция $\Cov(x_i, z_i)$ равна нулю. Мы оцениваем с помощью МНК две регрессии.

Регрессия 1:
\[
\hy_i = \hb_1 + \hb_2 x_i + \hb_3 z_i
\]

Регрессия 2:
\[
\hy_i = \hat \gamma_1 + \hat \gamma_2 x_i
\]

\begin{enumerate}
\item Верно ли, что $\hb_2$ совпадает с $\hat \gamma_2$?
\item Верно ли, что $\plim \hb_2 = \plim \hat \gamma_2$?
\end{enumerate}

\begin{sol}
В общем случае $\hb_2 \neq \hat \gamma_2$, однако $\plim \hb_2 = \plim \hat \gamma_2$.
\end{sol}
\end{problem}


\begin{problem}
Наблюдения представляют собой случайную выборку. Зависимые переменные $y_{t1}$ и $y_{t2}$ находятся из системы:

\[
\begin{cases}
y_{t1} = \beta_{11} + \beta_{12} x_t + \e_{t1} \\
y_{t2} = \beta_{21} + \beta_{22} z_t + \beta_{23} y_{t1} + \e_{t2}
\end{cases},
\]
где вектор ошибок $\e_t$ имеет совместное нормальное распределение
\[
\e_t \sim \cN\left(
\begin{pmatrix}
  0 \\
  0
\end{pmatrix};
\begin{pmatrix}
  1 & \rho \\
  \rho & 1
\end{pmatrix}
\right)
\]

Эконометресса Анжела оценивает с помощью МНК первое уравнение, а эконометресса Эвридика — второе.
\begin{enumerate}
\item Найдите пределы по вероятности получаемых ими оценок
\item Будут ли оценки состоятельными?
\end{enumerate}

\begin{sol}
\end{sol}
\end{problem}


\Closesolutionfile{solution_file}
