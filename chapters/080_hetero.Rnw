\chapter{Гетероскедастичность}


\begin{problem}
Что такое гетероскедастичность? Гомоскедастичность?
\end{problem}
\begin{solution}
\end{solution}

\begin{problem}
В модели $y_i = \beta_1 + \beta_2 x_i + \e_i$ присутствует гетероскедастичность вида $\Var(\e_i)=\sigma^2 x^2_i$. Как надо преобразовать исходные регрессоры и зависимую переменную, чтобы устранить гетероскедастичность? 
\end{problem}

\begin{solution}
Поделить зависимую переменную и каждый регрессор, включая единичный столбец, на $|x_i|$.
\end{solution}


\begin{problem}
В модели $y_i = \beta_1 + \beta_2 x_i + \e_i$ присутствует гетероскедастичность вида $\Var(\e_i)=\lambda |x_i|$. Как надо преобразовать исходные регрессоры и зависимую переменную, чтобы устранить гетероскедастичность? 
\end{problem}

\begin{solution}
Поделить зависимую переменную и каждый регрессор, включая единичный столбец, на $\sqrt{|x_i|}$.
\end{solution}


\begin{problem}
Известно, что после деления каждого уравнения регрессии $y_i = \beta_1 + \beta_2 x_i + \e_i$ на $x_i^2$ гетероскедастичность ошибок была устранена. Какой вид имела дисперсия ошибок, $\Var(\e_i)$?
\end{problem}

\begin{solution}
$\Var(\e_i)=cx_i^4$
\end{solution}


\begin{problem}
Известно, что после деления каждого уравнения регрессии $y_i = \beta_1 + \beta_2 x_i + \e_i$ на $\sqrt{x_i}$ гетероскедастичность ошибок была устранена. Какой вид имела дисперсия ошибок, $\Var(\e_i)$?
\end{problem}
\begin{solution}
$\Var(\e_i)=c x_i$
\end{solution}


\begin{problem}
Диаграмма рассеяния стоимости квартиры в Москве (в 1000\$) и общей площади квартиры имеет вид:

<<warning=FALSE>>=
ggplot(flats,aes(x=totsp,y=price))+geom_point()+
    labs(x="Общая площадь, кв. м.",
    y="Цена квартиры, 1000$")
@

Какие подходы к оцениванию зависимости имеет смысл посоветовать исходя из данного графика?
\end{problem}


\begin{solution}
По графику видно, что с увеличением общей площади увеличивается разброс цены. Поэтому разумно, например, рассмотреть следующие подходы:
\begin{enumerate}
\item Перейти к логарифмам, т.е. оценивать модель $\ln price_i=\beta_1+\beta_2 \ln totsp_i +\varepsilon_i$
\item Оценивать квантильную регрессию. В ней угловые коэффициенты линейной зависимости будут отличаться для разных квантилей переменной $price$.
\item Обычную модель линейной регрессии с гетероскедастичностью вида $Var(\varepsilon_i)=\sigma^2 totsp_i^2$
\end{enumerate} 
\end{solution}



\begin{problem}
По наблюдениям $x=(1,2,3)'$, $y=(2,-1,3)'$ оценивается модель $y=\b_1+\b_2 x+\e$. Ошибки $\e$ гетероскедастичны и известно, что $\Var(\e_i)=\sigma^2 \cdot x_i^2$. 
\begin{enumerate}
\item Найдите оценки $\hb_{ols}$ с помощью МНК и их ковариационную матрицу
\item Найдите оценки $\hb_{gls}$ с помощью обобщенного МНК и их ковариационную матрицу 
\end{enumerate}  
\end{problem}

\begin{solution}
\end{solution}




\begin{problem}
Для линейной регрессии $y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i + \e_i$ была
выполнена сортировка наблюдений по возрастанию переменной $x$. Исходная модель оценивалась по разным частям выборки:

\begin{tabular}{c|cccc}
Выборка & $\hb_1$ & $\hb_2$ & $\hb_3$ & $RSS$ \\
\hline 
$i=1,\ldots, 30$ & $1.21$ & $1.89$ & $2.74$ & $48.69$ \\ 
$i=1,\ldots, 11$ & $1.39$ & $2.27$ & $2.36$ & $10.28$ \\ 
$i=12,\ldots, 19$ & $0.75$ & $2.23$ & $3.19$ & $5.31$ \\ 
$i=20,\ldots, 30$ & $1.56$ & $1.06$ & $2.29$ & $14.51$ \\ 
\end{tabular} 

Известно, что ошибки в модели являются независимыми нормальными случайными величинами с нулевым математическим ожиданием. Протестируйте
ошибки на гетероскедастичность на уровне значимости 5\%.
\end{problem}


\begin{solution}
Протестируем гетероскедастичность ошибок при помощи теста Голдфельда-
Квандта. $H_0: \Var(\e_i)=\sigma^2$, $H_a: \Var(\e_i)=f(x_i)$

\begin{enumerate}
\item Тестовая статистика $GQ=\frac{RSS_3/(n_3-k)}{RSS_1/(n_1-k)}$, где $n_1=11$ --- число наблюдений в первой подгруппе, $n_3=11$ --- число наблюдений в
последней подгруппе, $k=3$ --- число факторов в модели, считая единичный столбец.
\item Распределение тестовой статистики при верной $H_0$: $GQ\sim F_{n_3-k,n_1-k}$
\item Наблюдаемое значение $GQ_{obs}=1.41$
\item Область, в которой $H_0$ не отвергается: $GQ\in [0;3.44]$
\item Статистический вывод: поскольку $GQ_{obs} \in [0;3.44]$, то на основании имеющихся наблюдений на уровне значимости 5\% основная гипотеза $H_0$ не может быть отвергнута. Таким образом, тест Голдфельда-Квандта не выявил гетероскедастичность.
\end{enumerate} 
\end{solution}


\begin{problem}
Для линейной регрессии $y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i + \e_i$ была
выполнена сортировка наблюдений по возрастанию переменной $x$. Исходная модель оценивалась по разным частям выборки:

\begin{tabular}{c|cccc}
Выборка & $\hb_1$ & $\hb_2$ & $\hb_3$ & $RSS$ \\
\hline 
$i=1,\ldots, 50$ & $1.16$ & $1.99$ & $2.97$ & $174.69$ \\ 
$i=1,\ldots, 21$ & $0.76$ & $2.25$ & $3.18$ & $20.41$ \\ 
$i=22,\ldots, 29$ & $0.85$ & $1.81$ & $3.32$ & $3.95$ \\ 
$i=30,\ldots, 50$ & $1.72$ & $1.41$ & $2.49$ & $130.74$ \\ 
\end{tabular} 

Известно, что ошибки в модели являются независимыми нормальными случайными величинами с нулевым математическим ожиданием. Протестируйте
ошибки на гетероскедастичность на уровне значимости 1\%.
\end{problem}

\begin{solution}
Протестируем гетероскедастичность ошибок при помощи теста Голдфельда-
Квандта. $H_0: \Var(\e_i)=\sigma^2$, $H_a: \Var(\e_i)=f(x_i)$

\begin{enumerate}
\item Тестовая статистика $GQ=\frac{RSS_3/(n_3-k)}{RSS_1/(n_1-k)}$, где $n_1=21$ --- число наблюдений в первой подгруппе, $n_3=21$ --- число наблюдений в
последней подгруппе, $k=3$ --- число факторов в модели, считая единичный столбец.
\item Распределение тестовой статистики при верной $H_0$: $GQ\sim F_{n_3-k,n_1-k}$
\item Наблюдаемое значение $GQ_{obs}=6.49$
\item Область, в которой $H_0$ не отвергается: $GQ\in [0;3.12]$
\item Статистический вывод: поскольку $GQ_{obs} \notin [0;3.12]$, то на основании имеющихся наблюдений на уровне значимости 1\% основная гипотеза $H_0$ отвергается. Таким образом, тест Голдфельда-Квандта выявил гетероскедастичность.
\end{enumerate} 
\end{solution}


\begin{problem}
Для линейной регрессии $y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i + \e_i$ была
выполнена сортировка наблюдений по возрастанию переменной $x$. Исходная модель оценивалась по разным частям выборки:

\begin{tabular}{c|cccc}
Выборка & $\hb_1$ & $\hb_2$ & $\hb_3$ & $RSS$ \\
\hline 
$i=1,\ldots, 30$ & $0.96$ & $2.25$ & $3.44$ & $52.70$ \\ 
$i=1,\ldots, 11$ & $1.07$ & $2.46$ & $2.40$ & $5.55$ \\ 
$i=12,\ldots, 19$ & $1.32$ & $1.01$ & $2.88$ & $11.69$ \\ 
$i=20,\ldots, 30$ & $1.04$ & $2.56$ & $4.12$ & $16.00$ \\ 
\end{tabular} 

Известно, что ошибки в модели являются независимыми нормальными случайными величинами с нулевым математическим ожиданием. Протестируйте
ошибки на гетероскедастичность на уровне значимости 5\%.
\end{problem}

\begin{solution}
Протестируем гетероскедастичность ошибок при помощи теста Голдфельда-
Квандта. $H_0: \Var(\e_i)=\sigma^2$, $H_a: \Var(\e_i)=f(x_i)$

\begin{enumerate}
\item Тестовая статистика $GQ=\frac{RSS_3/(n_3-k)}{RSS_1/(n_1-k)}$, где $n_1=11$ --- число наблюдений в первой подгруппе, $n_3=11$ --- число наблюдений в
последней подгруппе, $k=3$ --- число факторов в модели, считая единичный столбец.
\item Распределение тестовой статистики при верной $H_0$: $GQ\sim F_{n_3-k,n_1-k}$
\item Наблюдаемое значение $GQ_{obs}=2.88$
\item Область, в которой $H_0$ не отвергается: $GQ\in [0;3.44]$
\item Статистический вывод: поскольку $GQ_{obs} \in [0;3.44]$, то на основании имеющихся наблюдений на уровне значимости 5\% основная гипотеза $H_0$ не может быть отвергнута. Таким образом, тест Голдфельда-Квандта не выявил гетероскедастичность.
\end{enumerate} 
\end{solution}


\begin{problem}
Для линейной регрессии $y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i + \e_i$ была выполнена сортировка наблюдений по возрастанию переменной $x$. Исходная модель оценивалась по разным частям выборки:

\begin{tabular}{c|cccc}
Выборка & $\hb_1$ & $\hb_2$ & $\hb_3$ & $RSS$ \\

\hline 
$i=1,\ldots, 50$ & $0.93$ & $2.02$ & $3.38$ & $145.85$ \\ 
$i=1,\ldots, 21$ & $1.12$ & $2.01$ & $3.32$ & $19.88$ \\ 
$i=22,\ldots, 29$ & $0.29$ & $2.07$ & $2.24$ & $1.94$ \\ 
$i=30,\ldots, 50$ & $0.87$ & $1.84$ & $3.66$ & $117.46$ \\ 
\end{tabular} 

Известно, что ошибки в модели являются независимыми нормальными случайными величинами с нулевым математическим ожиданием. Протестируйте
ошибки на гетероскедастичность на уровне значимости 5\%.
\end{problem}
\begin{solution}
Протестируем гетероскедастичность ошибок при помощи теста Голдфельда-
Квандта. $H_0: \Var(\e_i)=\sigma^2$, $H_a: \Var(\e_i)=f(x_i)$

\begin{enumerate}
\item Тестовая статистика $GQ=\frac{RSS_3/(n_3-k)}{RSS_1/(n_1-k)}$, где $n_1=21$ --- число наблюдений в первой подгруппе, $n_3=21$ --- число наблюдений в
последней подгруппе, $k=3$ --- число факторов в модели, считая единичный столбец.
\item Распределение тестовой статистики при верной $H_0$: $GQ\sim F_{n_3-k,n_1-k}$
\item Наблюдаемое значение $GQ_{obs}=5.91$
\item Область, в которой $H_0$ не отвергается: $GQ\in [0;2.21]$
\item Статистический вывод: поскольку $GQ_{obs} \notin [0;2.21]$, то на основании имеющихся наблюдений на уровне значимости 5\% основная гипотеза $H_0$ отвергается. Таким образом, тест Голдфельда-Квандта выявил гетероскедастичность.
\end{enumerate} 
\end{solution}


\begin{problem}
Рассмотрим линейную регрессию $y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i + \e_i$ по 50 наблюдениям. При оценивании с помощью МНК были получены результаты: $\hb_1=1.21$, $\hb_2=1.11$, $\hb_3=3.15$, $R^2=0.72$.

Оценена также вспомогательная регрессия: $\he^2_i=\delta_1+\delta_2 x_i +\delta_3 z_i+\delta_4 x_i^2+\delta_5 z_i^2+\delta_6 x_i z_i + u_i$. Результаты оценивания следующие: $\hat{\delta}_1=1.50$, $\hat{\delta}_2=-2.18$,  $\hat{\delta}_3=0.23$,  $\hat{\delta}_4=1.87$,  $\hat{\delta}_5=-0.56$,  $\hat{\delta}_6=-0.09$,  $R^2_{aux}=0.36$ 


Известно, что ошибки в модели являются независимыми нормальными случайными величинами с нулевым математическим ожиданием. Протестируйте
ошибки на гетероскедастичность на уровне значимости 5\%.
\end{problem}

\begin{solution}
Протестируем гетероскедастичность ошибок при помощи теста Уайта. $H_0: \Var(\e_i)=\sigma^2$, $H_a: \Var(\e_i)=\delta_1+\delta_2 x_i +\delta_3 z_i+\delta_4 x_i^2+\delta_5 z_i^2+\delta_6 x_i z_i$.
\begin{enumerate}
\item Тестовая статистика $W=n\cdot R^2_{aux}$, где $n$ --- число наблюдений, $R^2_{aux}$ --- коэффициент детерминации для вспомогательной регрессии.
\item Распределение тестовой статистики при верной $H_0$: $W\sim \chi^2_{k_{aux}-1}$, где $k_{aux}=6$ --- число регрессоров во вспомогательной регрессии, считая константу.
\item Наблюдаемое значение тестовой статистики: $W_{obs}=18$
\item Область, в которой $H_0$ не отвергается: $W\in [0;W_{crit}]=[0;11.07]$
\item Статистический вывод: поскольку $W_{obs} \notin [0;11.07]$, то на основании имеющихся наблюдений на уровне значимости 5\% основная гипотеза $H_0$ отвергается. Таким образом, тест Уайта выявил гетероскедастичность.
\end{enumerate}
\end{solution}



\begin{problem}
Объясните, с какой целью используются стандартные ошибки в форме Уайта. Приведите развернутый ответ. Верно ли, что стандартные ошибки в форме Уайта позволяют
\begin{enumerate}
\item устранить гетероскедастичность?
\item корректно тестировать гипотезы относительно коэффициентов регрессии в условиях гетероскедастичности? 
\end{enumerate}
\end{problem}

\begin{solution}
\end{solution}


\begin{problem}
Объясните, с какой целью используются стандартные ошибки в форме Невье–Веста. Приведите развернутый ответ. Верно ли, что стандартные ошибки в форме Невье–Веста позволяют
\begin{enumerate}
\item устранить гетероскедастичность?
\item корректно тестировать гипотезы относительно коэффициентов регрессии в условиях гетероскедастичности? 
\end{enumerate}
\end{problem}

\begin{solution}
\end{solution}


\begin{problem}
Рассматривается модель $y_t=\beta_1+\e_t$, где ошибки $\e_t$  --- независимые
случайные величины с $\E(\e_t)=0$ и $\Var(\e_t)=t$. Найдите наиболее эффективную
оценку неизвестного параметра $\beta_1$ в классе линейных по $y$ и несмещенных оценок.
\end{problem}
\begin{solution}
\end{solution}

\begin{problem}
Рассматривается модель $y_t=\beta_1+\e_t$, где ошибки $\e_t$  --- независимые
случайные величины с $\E(\e_t)=0$ и $\Var(\e_t)=t^2$. Найдите наиболее эффективную
оценку неизвестного параметра $\beta_1$ в классе линейных по $y$ и несмещенных оценок.
\end{problem}
\begin{solution}
\end{solution}


\begin{problem}
Рассматривается модель $y_t=\beta_1 x_t+\e_t$, где ошибки $\e_t$  --- независимые
случайные величины с $\E(\e_t)=0$ и $\Var(\e_t)=t$. Найдите наиболее эффективную
оценку неизвестного параметра $\beta_1$ в классе линейных по $y$ и несмещенных оценок.
\end{problem}
\begin{solution}
\end{solution}


\begin{problem}
Рассматривается модель $y_t=\beta_1 x_t +\e_t$, где ошибки $\e_t$  --- независимые
случайные величины с $\E(\e_t)=0$ и $\Var(\e_t)=t^2$. Найдите наиболее эффективную
оценку неизвестного параметра $\beta_1$ в классе линейных по $y$ и несмещенных оценок.
\end{problem}
\begin{solution}
\end{solution}


\begin{problem}
Докажите, что в условиях гетероскедастичности МНК-
оценки остаются несмещенными.
\end{problem}

\begin{solution}
\end{solution}


\begin{problem}
Оценка коэффициентов обобщенного МНК имеет вид $\hb_{GLS}=(X'V^{-1}X)^{-1}X'V^{-1}y$, где $V=\Var(\e)$. Совпадает ли оценка $\hb_{GLS}$ с оценкой обычным МНК в условиях гомоскедастичности?
\end{problem}

\begin{solution}
\end{solution}


\begin{problem}
Модель $y_i=\beta_1 + \beta_2 x_i +\e_i$ оценивается по трём наблюдениям, $y=(9,3,6)$, $x=(1,2,4)$. Имеется гетероскедастичность вида $\Var(\e_i)=\sigma^2 x_i^2$, ошибки $\e_i$ нормально распределены. 
\begin{enumerate}
\item Оцените $\hb$ с помощью МНК проигнорировав гетероскедастичность. Постройте 95\% доверительный интервал для каждого коэффициента, проигнорировав гетероскедастичность
\item Оцените $\hb$ с помощью обобщенного МНК учтя гетероскедастичность. Постройте 95\% доверительный интервал для каждого коэффициента с учётом гетероскедастичности
\end{enumerate}
\end{problem}

\begin{solution}
\end{solution}


\begin{problem}
Рассмотрим модель $y_i=\beta_1+\beta_2 x_i+\e_i$, где ошибки $\e_i$ некоррелированы, $\E(\e_i)=0$, $\Var(\e_i)=\sigma^2_i$. Предлагается два способа оценить коэффициенты модели:
\begin{enumerate}
\item[WLS.] Взвешенный метод наименьших квадратов. Поделим каждое уравнение $y_i=\beta_1+\beta_2 x_i+\e_i$ на $\sigma_i$. Затем обычным методом наименьших квадратов в преобразованной модели $y_i/\sigma_i=\beta_1\cdot 1/\sigma_i+\beta_2 x_i/\sigma_i+\e_i/\sigma_i$ найдем оценки $\hb_{WLS}$.
\item[GLS.] Обобщенный метод наименьших квадратов. Оценки $\hb_{GLS}$ находим по формуле $\hb_{GLS}=(X'V^{-1}X)^{-1}X'V^{-1}y$, где 
\[
V=\Var(\e)=\begin{pmatrix}
\sigma^2_1 & 0 & 0 \\
0 & \ddots & 0 \\
0 & 0 & \sigma^2_n 
\end{pmatrix}
\]
\end{enumerate}
\begin{enumerate}
\item Докажите, что в матричном виде преобразование взвешенного МНК записывается как $V^{-1/2}y=V^{-1/2}X\beta+V^{-1/2}\e$.
\item Верно ли, что $\hb_{WLS}=\hb_{GLS}$?
\item Найдите $\E(\hb_{WLS})$, $\Var(\hb_{WLGS})$
\item В явном виде выпишите $\hb_{2,WLS}$
\end{enumerate}
\end{problem}

\begin{solution}
\end{solution}



\begin{problem}
Рассмотрим модель регрессии $y_i=\beta_1+\beta_2 x_i + \beta_3 z_i+\e_i$, в которой
ошибки $\e_i$ независимы и имеют нормальное распределение $N(0,\sigma^2)$. Для $n = 200$ наблюдений найдите
\begin{enumerate}
\item вероятность того, что статистика Уайта окажется больше 10,
\item ожидаемое значение статистики Уайта,
\item дисперсию статистики Уайта.   
\end{enumerate}
\end{problem}

\begin{solution}
$0.0752$, $5$, $10$
\end{solution}

\begin{problem}
Найдите число коэффициентов во вспомогательной регрессии, необходимой для выполнения теста Уайта, если число коэффициентов в исходной регрессии равно $k$, включая свободный член.
\end{problem}

\begin{solution}
$k(k+1)/2$
\end{solution}

\begin{problem} 
(Кирилл Фурманов) По 35 наблюдениям сотрудники НИИ оценили уравнение регрессии $y_i = \beta_1 + \beta_2 x_i + \e_i$ и рассчитали остатки $\e_i$. После того они приступили к диагностике возможных недостатков модели, обнаружили гетероскедастичность и решили её побороть.
\begin{enumerate}
\item[(a)] Самый младший научный сотрудник выдвинул предположение, что стандартное отклонение случайной составляющей может быть выражено так: $\sigma_{\e, i} = a x_i$, где $a$ --– неизвестный коэффициент. Каким образом нужно преобразовать исходное уравнение регрессии, чтобы избавиться от гетероскедастичности?
\item[(b)] Профессор решил перепроверить результаты и оценил регрессию: 
$$\hat{e}_i^2 = -0.3 + 0.08 x_i - 0.01 x_i^2, R^2 = 0.15$$
Свидетельствует ли полученный профессором результат о наличии гетероскедастичности?
\end{enumerate}
\end{problem}

\begin{solution}
\end{solution}


\begin{problem}
 Пусть $y_t = \beta x_t + \e$ где $\E(\e_t) = 0$ и известно, что оценки для параметров $\tilde{\beta} = \left( \sum_{t=1}^n y_t \right)/\left( \sum_{t=1}^n x_t \right)$ являются наилучшими (в смысле минимума дисперсии) среди линейных несмещенных оценок параметра $\beta$. Чему равна в этом случае матрица ковариаций вектора $\e$ с точностью до пропорциональности?
\end{problem}


\begin{solution}
Известно, что оценки параметров, получаемые по обобщённому методу наименьших квадратов, являются наилучшими, поэтому:
$\delta^2 \begin{bmatrix}
x_1 & 0\ldots0 & 0 \\
0 &  & 0 \\
  & \ldots & \\
0 &  & 0 \\
0 & 0\ldots0 & x_n \\
\end{bmatrix}$
\end{solution}

\begin{problem}
Для регрессии $y = X\beta + \e$ с $\E(\e) = 0$, $\Var(\e) = \Sigma \neq \sigma^2 I$, оцененной с помощью обобщённого метода наименьших квадратов, найдите ковариационную матрицу $\Cov(\hat{\beta}_{GLS}, \e)$
\end{problem}


\begin{solution}
\begin{multline}
\Cov(\hat{\beta}_{GLS}, \e) = \Cov \left( (X^T \Sigma^{-1} X)^{-1} X^T \Sigma^{-1} y, \e \right) = \\
\Cov \left( (X^T \Sigma^{-1} X)^{-1} X^T \Sigma^{-1} \e, \e \right) = \\ = (X^T \Sigma^{-1} X)^{-1} X^T \Sigma^{-1} \Cov(\e, \e) =\\
 (X^T \Sigma^{-1} X)^{-1} X^T \Sigma^{-1} \Sigma = (X^T \Sigma^{-1} X)^{-1} X^T
\end{multline}
\end{solution}


\begin{problem}
Найдите наиболее эффективную оценку коэффициента $\beta_1$ для модели $y_i = \beta_1 + \e$, $\E(\e_i) = 0$, $\E(\e_i\e_j) = 0$, $\Var(\e_i) = \sigma_{\e}^2 / x_i$, $x_i > 0$ в классе линейных несмещенных оценок
\end{problem}

\begin{solution}
Для нахождения эффективной оценки воспользуемся взвешенным методом наименьших квадратов. Разделим каждое из уравнений $y_i = \beta_1 + \e$ на корень из дисперсии $\e_i$ с тем, чтобы ошибки в полученных уравнениях имели равные дисперсии (в этом случае можно будет сослаться на т. Гаусса-Маркова). Итак, после деления i-го уравнения на величину $\sqrt{x_i}/\sigma_{\e}$, мы получаем:
$$\begin{bmatrix}
y_1 \sqrt{x_1}/\sigma_{\e} \\
y_2 \sqrt{x_2}/\sigma_{\e} \\
\ldots \\
y_n \sqrt{x_n}/\sigma_{\e} \\
\end{bmatrix} = \beta_1 \begin{bmatrix}
\sqrt{x_1}/\sigma_{\e} \\
\sqrt{x_2}/\sigma_{\e} \\
\ldots \\
\sqrt{x_n}/\sigma_{\e} \\
\end{bmatrix} + \begin{bmatrix}
\e_1 \sqrt{x_1}/\sigma_{\e} \\
\e_2 \sqrt{x_2}/\sigma_{\e} \\
\ldots \\
\e_n \sqrt{x_n}/\sigma_{\e} \\
\end{bmatrix}$$
Поскольку условия т. Гаусса-Маркова для последней модели выполнены, то МНК-оценка для последней модели будет наиболее эффективной. Поэтому
$$\hat{\beta_1} = \frac{\sum_{i=1}^n (y_i \sqrt{x_i}/\sigma_{\e})(\sqrt{x_i}/\sigma_{\e})}{\sum_{i=1}^n (\sqrt{x_1}/\sigma_{\e})} = \frac{\sum_{i=1}^n y_i x_i}{\sum_{i=1}^n x_i^2}$$
\end{solution}


\begin{problem}
Фурманов Кирилл. Исследователь оценил регрессионную модель $y_i = \beta_1 + \beta_2 x_{i2} + \beta_3 x_{i3} + \beta_4 x_{i4} + \e_i$ и провёл диагностику различных проблемных явлений. Результаты его стараний приведены ниже:

%\todo[inline]{Две картинки с графиками остатков}


Также $VIF_2 = 1.06$, $VIF_3 = 1.07$, $VIF_4 = 1.02$
\begin{enumerate}
\item[(a)] Определите, какие проблемные явления обнаружил исследователь. Обоснуйте свой ответ.
\item[(b)] Найдите коэффициент детерминации для регрессии: $x_{i2} = \gamma_1 + \gamma_2 x_{i3} + \gamma_3 x_{i4} + u_i$
\end{enumerate}
\end{problem}


\begin{solution}
\end{solution}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Новые задачи

\begin{problem}
В модели $y_i=\beta x_i+\e_i$ предполагается гетероскедастичность вида $\Var(\e_i)=\exp(\gamma_1+\gamma_2 x_i)$. 
\begin{enumerate}
\item Сформулируйте гипотезу о гомоскедастичности с помощью коэффициентов
\item Выведите в явном виде оценку максимального правдоподобия при предположении о гомоскедастичности
\item Выпишите условия первого порядка для оценки максимального правдоподобия без предположения о гомоскедастичности
\item Выведите в явном виде формулу для LM теста множителей Лагранжа
\end{enumerate}
\end{problem}

\begin{solution}
В предположении о гомоскедастичности, $\gamma_2=0$, оценка правдоподобия совпадает с МНК-оценкой, значит $\hb=\sum y_i x_i/ \sum x_i^2$. И $\hs^2_i=RSS/n$, значит $\hat{\gamma_1}=\ln(RSS/n)$.
\end{solution}




